{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 - Méthodes probabilistes et statistiques pour I.A.\n",
    "#### Polytechnique Montréal\n",
    "\n",
    "\n",
    "### Projet A2024\n",
    "\n",
    "-----\n",
    "\n",
    "# Prédiction de la consommation en carburant de voitures récentes\n",
    "\n",
    "### Contexte\n",
    "\n",
    "Dans le cadre de ce projet, on nous fournit un jeu de données comprenant différentes caractéristiques de véhicules à essence ainsi que leur consommation d'essence en L/100km.\n",
    "\n",
    "### Objectif\n",
    "\n",
    "L'objectif du projet est de prédire, pour un ensemble de données de validation, la consommation d'essence d'un véhicule en se fiant à ses autres caractéristiques.  Pour ce faire, nous explorerons différentes avenues tant au niveau du traitement des données d'entraînement qu'au niveau de la conception d'un modèle. \n",
    "\n",
    "### Données\n",
    "\n",
    "Les données utilisées pour inférer la consommation de carburant sont les suivantes :\n",
    "\n",
    "- `train.csv` : données d'un ensemble d'entraînement qui comprennent différentes caractéristiques de véhicules et leur consommation d'essence associée \n",
    "- `test.csv` : données d'un ensemble de validation qui comprennent tout sauf la consommation d'essence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par importer les librairies nécessaires à l'utilisation de ce calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Plots, StatsBase, StatsPlots, Random, StatsModels, GLM, LinearAlgebra, MultivariateStats, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite charger les données de l'ensemble d'entraînement et de l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") # ne contient pas la variable \"consommation\"\n",
    "\n",
    "Random.seed!(1234) # pour la reproductibilité\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) # 80% des données pour l'entraînement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) # échantillonnage aléatoire pour l'entraînement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) # échantillon de validation ; prend les données qui ne sont pas dans l'échantillon d'entraînement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(valid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate donc que les données ont été bien chargées, et que l'ensemble de test comprend également une colonne de moins que l'ensemble full_train, soit la colonne de consommation d'essence.  De plus, nous avons séparé le jeu de données d'entraînement en deux sous-groupes : 80% pour l'entraînement dans la variable \"train\", et le 20% restant pour assurer la validation dans la variable \"valid\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour continuer, nous avons créé quelques fonctions génériques qui seront utiles à plusieurs reprises plus loin dans le calepin.  Afin d'éviter des répétitions inutiles de ces procédés, et pour s'assurer de pouvoir retracer ces fonctions rapidement, elles sont regroupées sous cette rubrique \"helpers\".\n",
    "\n",
    "D'abord, nous avons réalisé en affichant les données à la section précédente que deux données numériques, la cylindrée et la consommation, étaient en format String plutôt que d'un type Float. Naturellement, cette incohérence dans le jeu de données nous empêchera de travailler avec celles-ci, et c'est pourquoi nous nous sommes munis d'un outil de conversion en Float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function safe_parse_float(x)\n",
    "    try\n",
    "        return parse(Float64, x)\n",
    "    catch\n",
    "        return missing\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, pour les données non numériques comme le type de véhicule, la transmission et la boîte, nous devons nous munir d'une méthode de conversion pour encoder ces données de façon à ce que le modèle d'apprentissage automatique puissent les traiter adéquatement.  La méthode que nous avons choisie est l'encodage \"one-hot\", qui consiste à créer une nouvelle colonne pour chaque catégorie et à assigner la valeur 1 à cette colonne si c'est la rangée correspond à cette catégorie, et la valeur 0 dans tous les autres cas.  Nous avons choisi la méthode one-hot afin d'éviter les problèmes que l'autre méthode d'encodage populaire que nous considérions, l'encodage ordinal, peut poser, notamment les biais de magnitude (0 et 1 sont des valeurs neutres qui ne discriminent pas entre les catégories, contrairement aux valeurs ordinales 1, 2, 3, ... qui peuvent influencer les prédictions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_encode(df, cols, levels_dict)\n",
    "    for col in cols\n",
    "        levels_col = levels_dict[col]\n",
    "        for level in levels_col\n",
    "            new_col = Symbol(string(col) * \"_\" * string(level))\n",
    "            df[!, new_col] = ifelse.(df[!, col] .== level, 1.0, 0.0)\n",
    "        end\n",
    "        select!(df, Not(col))\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'accélérer le développement de notre solution, nous nous sommes également munis d'une fonction qui applique un pre-processing de base aux jeux de données pertinents.  Cette méthode commencer par remplacer les virgules par des points dans les colonnes numériques qui sont en String par défaut dans les jeux de données, puis applique la conversion en Float directement et retire les valeurs manquantes à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function default_prerocessing(data)\n",
    "\n",
    "# distinguer les jeux de données ayant la colonne \"consommation\" de ceux qui ne l'ont pas\n",
    "datasets_with_consommation = [data]\n",
    "\n",
    "# dans tous les jeux de données, remplacer les virgules par des points dans 'cylindree' pour pouvoir convertir en float ensuite\n",
    "for df in [data]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# idem pour les jeux de données ayant la colonne 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# convertir 'cylindree' en float dans tous les jeux de données\n",
    "for df in [data]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# convertir 'consommation' en float dans les jeux de données ayant la colonne 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# retirer les valeurs manquantes dans tous les jeux de données\n",
    "for df in [data]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par nous familiariser avec les données à notre disposition. Dans cette section, nous allons explorer différentes pistes qui pourraient potentiellement avoir un impact positif sur nos prédictions, que ce soit de répérer des données éloignées du reste de l'ensemble, de répérer des tendances, de détecter des instances de multicolinéarité, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape pour traiter les données est de copier les données d'entraînement dans une variable \"data\" afin d'éviter de corrompre les données originales lors de nos manipulations. On peut ensuite retirer les variables manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire une copie initiale du dataframe\n",
    "data = deepcopy(train)\n",
    "\n",
    "# retirer les colonnes ayant des données vides de notre dataframe\n",
    "data = dropmissing(data)\n",
    "\n",
    "default_prerocessing(data)\n",
    "\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons commencer par analyser chacune des variables explicatives potentielles en détail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Année"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première variable explicative est l'année de fabrication du véhicule. Nous avons commencé par regarder la tendance de la consommation d'essence au fil des ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:annee,\n",
    "    y=:consommation,\n",
    "    Geom.boxplot,\n",
    "    Guide.title(\"Consommation d'essence en fonction de l'année du véhicule\"),\n",
    "    Guide.xlabel(\"Année\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tirer quelques observations de ce diagramme. D'abord, les données de l'ensemble d'entraînement sont réparties sur une période de seulement 10 ans, soit de 2014 à 2024. Ceci fait en sorte que les consommations d'essence correspondantes varieront peu d'une année à l'autre, car les véhicules ne se sont pas améliorés technologiquement de façon assez significative sur une aussi courte période pour que l'année de fabrication ait une incidence notable sur la consommation d'essence. De plus, lorsqu'on observe le diagramme, il est difficile de remarquer une tendance claire dans la variation de la consommation d'essence sur la période de 10 ans. La consommation d'essence semblait être à la hausse entre 2018 et 2020, puis s'est stabilisée avant de rechuter en 2023. Ces variations nous semblent difficiles à modéliser. Pour toutes ces raisons, il nous semble initialement que l'année de fabrication soit une variable explicative de faible impact sur les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous nous sommes questionné quant à la grosseur des chiffres reliées à l'année dans un modèle. En effet, les autres données numériques étant le nombre de cylindres et la cylindrée, qui ont tous les deux des valeurs nettement inférieures à un chiffre comme 2020, nous nous demandions si cette disparité pouvait avoir un impact sur la qualité de nos prédictions. Nous avons donc opté pour la stratégie de changer la variable explicative de l'année de fabrication pour une variable d'âge, qui serait entre 1 et 10 ans, et qui serait beaucoup plus proche des valeurs des autres variables explicatives. Ci-dessous se trouve notre façon de procéder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age = 2024 .- data.annee\n",
    "\n",
    "select!(data, Not(:annee))\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de ces données, nous avons essayé de remplacer l'année de fabrication par l'âge du véhicule dans notre modèle le plus performant. Nous avons noté une amélioration de ${10}^{-12}$ de notre RMSE. Il va donc sans dire que cette modification de nos variables explicatives était totalement inutile. Nous garderons donc l'année de fabrication pour la suite de nos tests, bien que nous ayons peu d'espoir que cette variable se retrouve dans le modèle final étant donné sa faible corrélation avec la consommation d'essence pour toutes les raisons mentionnées ci-haut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Type de véhicule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_categories = unique(skipmissing(data[:, :type]))\n",
    "occurences = [sum(skipmissing(data[:, :type]) .== category) for category in unique_categories]\n",
    "occurences = DataFrame(category = unique_categories, occurences = occurences)\n",
    "println(occurences)\n",
    "\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:type,\n",
    "    y=:consommation,\n",
    "    color=:type,\n",
    "    Geom.boxplot,\n",
    "    Guide.title(\"Consommation d'essence par type de véhicule\"),\n",
    "    Guide.xlabel(\"Type de véhicule\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphique des occurences selon les différents types de véhicules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    occurences,\n",
    "    x=:category,\n",
    "    y=:occurences,\n",
    "    Geom.bar,\n",
    "    Guide.title(\"Répartition des types de véhicules\"),\n",
    "    Guide.xlabel(\"Type de véhicule\"),\n",
    "    Guide.ylabel(\"Occurrences\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des moyennes de consommation par type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = combine(groupby(data, :type), :consommation => mean => :mean_consommation)\n",
    "println(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df mean_values bar(:type, :mean_consommation, xlabel=\"Type de véhicule\", ylabel=\"Consommation Moyenne\", title=\"Consommation Moyenne par Type de Véhicule\", legend=false, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir des 2 derniers graphique sur la consommation en fonction du type de véhicule et sur la consommation moyenne en fonction du type de véhicule, il est possbile de remarqué des similarités\n",
    "sur la consommation de certains types de véhicules. Afin de contrer le fait que certaines catégories ont très peu d'observations, ce qui rend l'interprétation des tendances générales plus\n",
    "difficiles en raison du bruit, certaines catégories similaires ont été regroupées. Cela permet aussi de contribuer à réduire la multicolinéarité en réduisant le nombre de variables explicatives similaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"monospace\", \"camionnette_petit\",]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons les performances de ces nouvelles catégories dans un modèle de régression linéaire, en les comparant avec les performances des types de véhicules séparés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithCategorie = deepcopy(data)\n",
    "\n",
    "dataWithCategorie[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in dataWithCategorie[:, :type]]\n",
    "categorical_cols = [:categorie_vehicule,]\n",
    "\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(dataWithCategorie[!, col])\n",
    "end\n",
    "\n",
    "data_type_encoded = one_hot_encode(dataWithCategorie, categorical_cols, levels_dict)\n",
    "model = lm(@formula(consommation ~ categorie_vehicule_petits_véhicules + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens), dataWithCategorie)\n",
    "\n",
    "dataWithCategorie.predicted = predict(model)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((dataWithCategorie.consommation .- dataWithCategorie.predicted).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithType = deepcopy(data)\n",
    "\n",
    "categorical_cols = [:type,]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(dataWithType[!, col])\n",
    "end\n",
    "\n",
    "data_type_encoded = one_hot_encode(dataWithType, categorical_cols, levels_dict)\n",
    "\n",
    "model = lm(@formula(consommation ~ type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte + type_VUS_standard + type_monospace + \n",
    "                    type_camionnette_petit + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard), dataWithType)\n",
    "\n",
    "#Prédire les valeurs de consommation pour tracer la ligne\n",
    "dataWithType.predicted = predict(model)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((dataWithType.consommation .- dataWithType.predicted).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorque seulement ces nouvelles catégories sont incluses dans le modèle elles performent moins bien que lorsque seulement les types originals sont icnlus dans le modèle, autant au niveau du R^2 que du RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# . Consommation par Type de Véhicule et Cylindrée\n",
    "# Graphique : Scatter plot avec la consommation en fonction de la cylindrée, catégorisée par type de véhicule (utilisez des couleurs ou des formes de points différentes pour les types).\n",
    "# Utilité : Identifier si certains types de véhicules ont une consommation plus élevée à cause d'une cylindrée importante.\n",
    "\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=:consommation,\n",
    "    color=:type,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée, catégorisée par type de véhicule\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    "    Guide.colorkey(\"Type de véhicule\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Proportions de Types de Véhicules\n",
    "# Graphique : Diagramme circulaire (pie chart) ou histogramme empilé (stacked bar chart).\n",
    "# Utilité : Permet de visualiser la répartition des occurrences des différents types de véhicules dans l'ensemble de données.\n",
    "# Axe X : Type de véhicule.\n",
    "# Axe Y : Nombre d'occurrences ou proportion.\n",
    "\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    occurences,\n",
    "    x=:category,\n",
    "    y=:occurences,\n",
    "    Geom.bar,\n",
    "    Guide.title(\"Répartition des types de véhicules\"),\n",
    "    Guide.xlabel(\"Type de véhicule\"),\n",
    "    Guide.ylabel(\"Occurrences\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. grouper break petit avec minicompacte (enlever outliers)\n",
    "\n",
    ". Consommation par Type de Véhicule et Cylindrée\n",
    "Graphique : Scatter plot avec la consommation en fonction de la cylindrée, catégorisée par type de véhicule (utilisez des couleurs ou des formes de points différentes pour les types).\n",
    "Utilité : Identifier si certains types de véhicules ont une consommation plus élevée à cause d'une cylindrée importante.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule moyen :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "vehicule_moyenne = filter(row -> row.type == \"voiture_moyenne\", data)\n",
    "Gadfly.plot(vehicule_moyenne, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type VUS_petit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "vehicule_VUSp = filter(row -> row.type == \"VUS_petit\", data)\n",
    "Gadfly.plot(vehicule_VUSp, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule compacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "voiture_compacte = filter(row -> row.type == \"voiture_compacte\", data)\n",
    "Gadfly.plot(voiture_compacte, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule 2 places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "voiture_deux_places = filter(row -> row.type == \"voiture_deux_places\", data)\n",
    "Gadfly.plot(voiture_deux_places, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule camionnette standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "camionnette_standard = filter(row -> row.type == \"camionnette_standard\", data)\n",
    "Gadfly.plot(camionnette_standard, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule mini compacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "voiture_minicompacte = filter(row -> row.type == \"voiture_minicompacte\", data)\n",
    "Gadfly.plot(voiture_minicompacte, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule VUS standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "VUS_standard = filter(row -> row.type == \"VUS_standard\", data)\n",
    "Gadfly.plot(VUS_standard, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consommation en fonction du type véhicule sous-compacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "voiture_sous_compacte = filter(row -> row.type == \"voiture_sous_compacte\", data)\n",
    "Gadfly.plot(voiture_sous_compacte, x=:age, y=:consommation, color=:type, Geom.point, Geom.smooth(method=:loess), Guide.xlabel(\"Année\"), Guide.ylabel(\"Consommation (L/100km)\"), Guide.colorkey(\"Type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cylindrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Généralement, la cylindée d'un véhicule est hautement corrélée à la consommation d'essence de celui-ci. Toutefois, la cylindrée est une variable continue avec énormément de valeurs uniques, ce qui peut compliqué la modélisation de la consommation d'essence. De plus, la distibuion des échantillions est asymétrique. Nous avons donc décidé d'étudier la nécessité de transformer cette variable en une variable catégorielle. Pour ce faire, nous avons d'abord regardé la distribution des cylindrées dans notre ensemble de données. \n",
    "\n",
    "L'idée est de créer des catégories de cylindrées, par exemple, les véhicules avec une cylindrée de moins de 2L, entre 2L et 3L, et plus de 3L. Nous avons donc créé un histogramme de la distribution des cylindrées pour nous aider à déterminer les catégories à utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "#occurences of each cylindree\n",
    "unique_cylindree = unique(skipmissing(data[:, :cylindree]))\n",
    "occurences_cylindree = [sum(skipmissing(data[:, :cylindree]) .== cylindree) for cylindree in unique_cylindree]\n",
    "occurences_cylindree = DataFrame(cylindree = unique_cylindree, occurences = occurences_cylindree)\n",
    "\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    occurences_cylindree,\n",
    "    x=:cylindree,\n",
    "    y=:occurences,\n",
    "    Geom.bar,\n",
    "    Guide.title(\"Répartition des cylindrées\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Occurrences\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentionné, la distribution des cylindrées est très asymétrique, avec une majorité de véhicules ayant une cylindrée de moins de 3L. \n",
    "\n",
    "Avant d'essayer de corriger cette asymétrie échantillonale, nous allons commencer pas étudier la relation entre la cylindrée et la consommation d'essence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster un modèle de régression linéaire\n",
    "model = lm(@formula(consommation ~ cylindree), data)\n",
    "\n",
    "# Prédire les valeurs de consommation pour tracer la ligne\n",
    "data.predicted = predict(model)\n",
    "\n",
    "# Tracer avec Gadfly\n",
    "p = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    layer(data, x=:cylindree, y=:predicted, Geom.line, Theme(default_color=\"red\")),\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")\n",
    "\n",
    "display(p)\n",
    "#print model Stats r2 score, \n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((data.consommation .- data.predicted).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse)\n",
    "\n",
    "# calcul des résidus\n",
    "res = data.consommation .- data.predicted\n",
    "\n",
    "p1 = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=res,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Résidus de la régression linéaire\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Résidus\"),\n",
    ")\n",
    "display(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, il semble y avoir une relation croissante entre la cylindrée et la consommation de carburant. C'est ce qui était attendu, mais nous remarquons que la relation n'est pas parfaitemnt linéaire. Si nous voulons respecter le principe de linéarité, nous devons transformer la variable explicative pour respecter l'hypothèses 1. Pour ce faire, nous allons appliquer le logarithme des cylindrées pour voir si cela améliore la linéarité de la relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply log transformation to cylindree\n",
    "data.cylindree = log.(data.cylindree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster un modèle de régression linéaire\n",
    "model = lm(@formula(consommation ~ cylindree), data)\n",
    "\n",
    "# Prédire les valeurs de consommation pour tracer la ligne\n",
    "data.predicted = predict(model)\n",
    "\n",
    "# Tracer avec Gadfly\n",
    "p = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    layer(data, x=:cylindree, y=:predicted, Geom.line, Theme(default_color=\"red\")),\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    "    Guide.colorkey(\"Catégorie de cylindrée\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#occurences per categorize_cylindree\n",
    "unique_cylindree_cat = unique(skipmissing(data[:, :cylindree_cat]))\n",
    "occurences_cylindree_cat = [sum(skipmissing(data[:, :cylindree_cat]) .== cylindree_cat) for cylindree_cat in unique_cylindree_cat]\n",
    "occurences_cylindree_cat = DataFrame(cylindree_cat = unique_cylindree_cat, occurences = occurences_cylindree_cat)\n",
    "\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    occurences_cylindree_cat,\n",
    "    x=:cylindree_cat,\n",
    "    y=:occurences,\n",
    "    Geom.bar,\n",
    "    Guide.title(\"Répartition des catégories de cylindrées\"),\n",
    "    Guide.xlabel(\"Catégorie de cylindrée\"),\n",
    "    Guide.ylabel(\"Occurrences\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appliquer le logaritme sur la cylindree\n",
    "data.cylindree = log.(data.cylindree)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((data.consommation .- data.predicted).^2))\n",
    "println(\"RMSE: \", rmse)\n",
    "\n",
    "# calcul des résidus\n",
    "res = data.consommation .- data.predicted\n",
    "\n",
    "p1 = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=res,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Résidus de la régression linéaire\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Résidus\"),\n",
    ")\n",
    "display(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, la relation entre la consommation d'essence et la cylindrée semble être plus linéaire après avoir appliqué le logarithme. Nous allons donc utiliser cette transformation pour la suite de notre analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nombre de cylindres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons maintenant une autre variable numérique : le nombre de cylindres du moteur. Commençons par déterminer combien de variables uniques existent pour cette variable explicative potentielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nb_cylindres = unique(data[:, :nombre_cylindres])\n",
    "occurences = [sum(data[:, :nombre_cylindres] .== nb_cylindres) for nb_cylindres in unique_nb_cylindres]\n",
    "occurences = DataFrame(nb_cylindres = unique_nb_cylindres, occurences = occurences)\n",
    "sort!(occurences, :occurences, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le constater, la grande majorité des véhicules étudiés ont 4 cylindres (148), 6 cylindres (87), 8 cylindres (51) ou 3 cylindres (24). Seuls quelques véhicules ont un plus grand nombre de cylindres (3 véhicules de 12 cylindres et 3 véhicules de 10 cylindres), et une seul véhicule a 5 cylindres. Pour ces valeurs pour lesquelles nous disposons de moins de données d'entraînement, il est donc possible de penser que le modèle sera moins efficace dans ses prédictions. Ce sera une hypothèse que nous considérerons plus loin dans l'entraînement de nos modèles. On pourrait décider d'omettre ces données en appliquant la modification suivante au dataframe (conserver la valeur seulement si elle est associée à plus de 5 occurences):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = occurences[occurences.occurences .> 5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi visualiser ces données sous forme de diagramme pour obtenir une meilleure compréhension de celles-ci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nombre_cylindres = log.(data.nombre_cylindres)\n",
    "\n",
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Consommation d'essence en fonction du nombre de cylindres du véhicule (log)\"),\n",
    "    Guide.xlabel(\"Nombre de cylindres (log)\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(consommation ~ nombre_cylindres), data)\n",
    "\n",
    "data.predicted = predict(model)\n",
    "\n",
    "p = Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    layer(data, x=:nombre_cylindres, y=:predicted, Geom.line, Theme(default_color=\"red\")),\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")\n",
    "\n",
    "display(p)\n",
    "\n",
    "\n",
    "p1 = Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=res,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Résidus de la régression linéaire\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Résidus\"),\n",
    ")\n",
    "\n",
    "display(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit donc que plus le nombre de cylindres est grand, plus la consommation d'essence moyenne a tendance à augmenter aussi. Compte tenu de cette observation et du fort coefficient de corrélation entre la consommation et le nombre de cylindres, il semble que ce dernier constitue une variable explicative de fort intérêt pour notre modèle prédictif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transmission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ce qui concerne le type de transmission, nous avons commencé par observer la distribution des catégories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [data]\n",
    "    println(\"Nombre d'observations par type de transmission :\")\n",
    "    println(combine(groupby(df, :transmission), nrow))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, les types de transmission sont représentées inégalement dans l'ensemble de données. Les transmissions integrale et à traction sont largement représentées, tandis que les transmissions à propulsion et 4x4 sont sous-représentées. Cela nous mène à questionner l'effet de ce manque sur les prédictions. Effectivement, si les types de transmission sont corrélés à la consommation d'essence, le fait que certaines catégories soient sous-représentées pourrait biaiser nos prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme de la consommation moyenne en fonction du type de transmission\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "\n",
    "mean_consommation = combine(groupby(data, :transmission), :consommation => mean => :mean_consommation)\n",
    "# moyenne par type de transmission\n",
    "println(mean_consommation)\n",
    "\n",
    "Gadfly.plot(\n",
    "    mean_consommation,\n",
    "    x=:transmission,\n",
    "    y=:mean_consommation,\n",
    "    Geom.bar,\n",
    "    Guide.xlabel(\"Transmission\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction du type de transmission\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme, les prédictions risquent d'être biaisées vers des valeurs associées aux classes majoritaires (\"integrale\" ou \"traction\"), nous pourrions poser l'hypothèse que le modèle risque de sous-estimer non seulement la consommation des véhicules avec une transmission 4x4 et propulsion, mais aussi les prédictions globales en raison de la forte représentation de la transmission traction. (Voir histogramme de la consommation par type de transmission). Pour pallier à ce problème, nous pourrions envisager de pondérer ou de regrouper les classes de transmission pour équilibrer les données. Par exemple, nous pourrions ajouter un poids élevé à la classe \"4x4\" et un poids plus faible à la classe \"Traction\" pour compenser leur représentation respective. Nous pourrions également regrouper les classes \"Intégrale\" et \"Propulsion\" en une seule catégorie pour augmenter leur représentation dans l'ensemble de données, si leur distinction n'apporte pas de valeur ajoutée au modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle de régression linéaire de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prerocessing(train)\n",
    "default_prerocessing(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(consommation ~  transmission_integrale + transmission_traction + transmission_propulsion), train) #Me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = GLM.predict(modelA, valid)\n",
    "train_prediction = GLM.predict(modelA, train)\n",
    "# Trouver la moyenne de prediction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "mean_prediction_train = mean(train_prediction)\n",
    "# Remplacer les missing par la moyenne\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "train_prediction = coalesce.(train_prediction, mean_prediction_train)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse_valid = sqrt(mean((valid_prediction - valid.consommation).^2))\n",
    "println(\"RMSE: \", rmse_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boîte\n",
    "\n",
    "Terminons notre analyse en regardant la dernière variable explicative potentielle avec laquelle nous pouvons travailler, soit la boîte du moteur.  Cette variable peut prendre deux valeurs seulement : automatique ou manuelle.  Commençons par comptabiliser le nombre d'occurences de chaque type au sein de notre ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(data, :boite), nrow => :count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate donc qu'il y a beaucoup plus d'observations dans la catégorie des véhicules automatiques (268) que pour les véhicules manuels (49). Regardons maintenant la consommation d'essence associée à chacun des types de boîte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:boite,\n",
    "    y=:consommation,\n",
    "    Geom.boxplot,\n",
    "    Guide.xlabel(\"Boîte\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction du type de boîte\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate ici que les deux boîtes se comportent de manière similaire au niveau de la consommation moyenne, avec un écart interquartile un peu plus important pour les véhicules automatiques que pour les véhicules manuels. La variance de la distribution de véhicules automatiques est donc plus grande. On constate aussi la présence d'une donnée abherrante dans la distribution de données du côté manuel, qui pourrait gagner à être retirée lors de l'entraînement du modèle.  Puisque la boîte en soi ne nous informe que très peu sur la consommation d'essence d'un véhciule, on s'intéresse maintenant à la relation entre cette variable et d'autres éléments du jeu de données, notamment le type de véhicule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(data,\n",
    "    x = :type,\n",
    "    y = :consommation,\n",
    "    color = :boite,\n",
    "    Geom.point,\n",
    "    Scale.x_discrete(labels=identity),\n",
    "    Theme(bar_spacing=0.7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qu'on constate en observant ce graphique, c'est que pour certains types de véhicules, il est impossible que la boîte soit manuelle dans notre jeu de données d'entraînement. Cela fait en sorte qu'il existe possiblement une lacune dans la collecte de données qui ne sont pas assez représentatives, ou alors qu'il s'agit d'un phénomène qu'on pourrait constater en industrie.  Dans tous les cas, cette disparité entre les types de véhicule au niveau de la boîte peut emmener le modèle à faire des prédictions moins fiables pour le types de véhicules n'ayant pas des données à la fois maunelles et automatiques comme les VUS ou les camionnettes. De plus, on ne semble pas détecter que pour un ou des types de véhicules en particulier, le type de boîte ait un gros impact sur la consommation d'essence, pusique les points jaunes se retrouvent souvent au milieu des points bleus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = combine(groupby(data, [:cylindree, :boite]), \n",
    "    :consommation => mean => :avg_consumption)\n",
    "\n",
    "Gadfly.plot(aggregated_data,\n",
    "    x = :cylindree,\n",
    "    y = :avg_consumption,\n",
    "    color = :boite,\n",
    "    Geom.line,\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction de la cylindrée et du type de boîte\"),\n",
    "    Theme(default_color=\"blue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = combine(groupby(data, [:cylindree, :type]), \n",
    "    :consommation => mean => :avg_consumption)\n",
    "\n",
    "Gadfly.plot(aggregated_data,\n",
    "    x = :cylindree,\n",
    "    y = :avg_consumption,\n",
    "    color = :type,\n",
    "    Geom.line,\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction de la cylindrée et du type de véhicule\"),\n",
    "    Theme(default_color=\"blue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE de base: 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Approche A: Ajustement de poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prerocessing(train)\n",
    "default_prerocessing(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(train, :transmission), nrow => :nrow)\n",
    "\n",
    "# Step 2: Calculate total number of observations and number of classes\n",
    "total_samples = sum(counts.nrow)\n",
    "num_classes = nrow(counts)\n",
    "\n",
    "# Step 3: Compute weights for each transmission type\n",
    "counts.Weight = total_samples ./ (num_classes .* counts.nrow)\n",
    "\n",
    "# Step 4: Merge weights back into the original DataFrame\n",
    "train = leftjoin(train, counts[:, [:transmission, :Weight]], on=:transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle avec les poids\n",
    "train = dropmissing(train)\n",
    "\n",
    "modelA = fit(LinearModel, @formula(consommation ~ transmission_propulsion + transmission_traction + transmission_integrale + transmission_4x4), train, wts = train.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = GLM.predict(modelA, valid)\n",
    "train_prediction = GLM.predict(modelA, train)\n",
    "# Trouver la moyenne de prediction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "mean_prediction_train = mean(train_prediction)\n",
    "# Remplacer les missing par la moyenne\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "train_prediction = coalesce.(train_prediction, mean_prediction_train)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse_valid = sqrt(mean((valid_prediction - valid.consommation).^2))\n",
    "rmse_train = sqrt(mean((train_prediction - train.consommation).^2))\n",
    "println(\"RMSE train: \", rmse_train)\n",
    "println(\"RMSE valid: \", rmse_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Approche B: Combinaison de catégories similaires \n",
    "\n",
    "Nous devons tester la significativité statistique de la différence entre les moyennes des catégories de transmission. Pour ce faire, nous avons effectué un test de student pour comparer les moyennes de consommation d'essence entre les différentes catégories de transmission. Ce test ne dicte qu'il faut regrouper de manière absolue, mais dans le cas où les moyennes sont significativement différentes, cela pourrait être une bonne idée de regrouper les catégories pour réduire le nombre de variables explicatives et potentiellement améliorer les prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prerocessing(train)\n",
    "default_prerocessing(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer la moyenne\n",
    "\n",
    "function t_test_equal_variances(group1, group2)\n",
    "    # Tailles des échantillons\n",
    "    n1 = length(group1)\n",
    "    n2 = length(group2)\n",
    "\n",
    "    # Moyennes des deux groupes\n",
    "    μ1 = mean(group1)\n",
    "    μ2 = mean(group2)\n",
    "\n",
    "    # Variances des deux groupes\n",
    "    s1² = var(group1)\n",
    "    s2² = var(group2)\n",
    "\n",
    "    # Variance combinée pondérée\n",
    "    sp² = ((n1 - 1) * s1² + (n2 - 1) * s2²) / (n1 + n2 - 2)\n",
    "\n",
    "    # Statistique t\n",
    "    t_stat = (μ1 - μ2) / sqrt(sp² * (1 / n1 + 1 / n2))\n",
    "\n",
    "    # Degrés de liberté\n",
    "    df = n1 + n2 - 2\n",
    "\n",
    "    # p-valeur approximative (bilatérale) avec la loi de Student\n",
    "    # Approximation pour t-distribution : 2 * (1 - cdf(gaussian, abs(t_stat)))\n",
    "    # ou intégrer avec des librairies de tables t pour une solution complète.\n",
    "    return t_stat, df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_integrale = train[train.transmission .== \"integrale\", :consommation]\n",
    "group_4x4 = train[train.transmission .== \"4x4\", :consommation]\n",
    "group_propulsion = train[train.transmission .== \"propulsion\", :consommation]\n",
    "\n",
    "\n",
    "t_stat1, df1 = t_test_equal_variances(group_integrale, group_4x4)\n",
    "t_stat2, df2 = t_test_equal_variances(group_integrale, group_propulsion)\n",
    "\n",
    "absolut_t_stat1 = abs(t_stat1)\n",
    "absolut_t_stat2 = abs(t_stat2)\n",
    "\n",
    "pvalue1 = 2 * (1 - cdf(TDist(df1), absolut_t_stat1))\n",
    "pvalue2 = 2 * (1 - cdf(TDist(df2), absolut_t_stat2))\n",
    "\n",
    "println(\"----Goupe integrale-4x4----\")\n",
    "println(\"Statistique t: $absolut_t_stat1\")\n",
    "println(\"p-valeur  : $pvalue1\")\n",
    "println(\"Degrés de liberté : $df1\")\n",
    "println(\"----Goupe integrale-propulsion----\")\n",
    "println(\"Statistique t: $absolut_t_stat2\")\n",
    "println(\"p-valeur  : $pvalue2\")\n",
    "println(\"Degrés de liberté : $df2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le test de student nous donne une p-value > 0.05, nous ne pouvons pas rejeter l'hypothèse nulle selon laquelle les moyennes de consommation d'essence entre les différentes catégories de transmission sont égales. Cela signifie que les différences de consommation d'essence entre les catégories de transmission (integralle-4x4 et integrale-propulsion) ne sont pas statistiquement significatives. Par conséquent, nous pourrions regrouper les catégories de transmission similaires pour augmenter leur représentation dans l'ensemble de données et potentiellement améliorer les prédictions. Certains tests devront être effectués pour déterminer si cette modification améliore réellement les prédictions.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the grouped categories\n",
    "# if transmission is 4x4, change for integrale\n",
    "train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)\n",
    "valid.transmission = ifelse.(valid.transmission .== \"4x4\", \"integrale\", valid.transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.transmission = ifelse.(train.transmission .== \"propulsion\", \"integrale\", train.transmission)\n",
    "valid.transmission = ifelse.(valid.transmission .== \"propulsion\", \"integrale\", valid.transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "\n",
    "println(names(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB = lm(@formula(consommation ~ transmission_integrale + transmission_traction), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "train_prediction = GLM.predict(modelB, train)\n",
    "valid_prediction = GLM.predict(modelB, valid)\n",
    "\n",
    "# # Trouver la moyenne de prediction\n",
    "# mean_prediction = mean(valid_prediction)\n",
    "# mean_prediction_train = mean(train_prediction)\n",
    "# # Remplacer les missing par la moyenne\n",
    "# valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "# train_prediction = coalesce.(train_prediction, mean_prediction_train)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse_valid = sqrt(mean((valid_prediction - valid.consommation).^2))\n",
    "rmse_train = sqrt(mean((train_prediction - train.consommation).^2))\n",
    "println(\"RMSE train: \", rmse_train)\n",
    "println(\"RMSE valid: \", rmse_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrélation entre les variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons une meilleure idée de l'impact de chaque variable explicative sur la consommation d'essence, il serait intéressant de porter notre attention sur la corrélation entre ces variables. En effet, si deux variables explicatives sont fortement corrélées, cela pourrait poser problème pour la modélisation de la consommation d'essence. En effet, cela pourrait introduire du bruit dans le modèle et nous devrions retirer une des deux variables pour éviter ce problème. Nous allons donc calculer la matrice de corrélation entre les variables explicatives pour voir si ce problème se pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [:annee, :nombre_cylindres, :cylindree, :consommation]\n",
    "\n",
    "M = cor(Matrix(data[:, numeric_cols]))\n",
    "\n",
    "# Afficher la matrice de corrélation\n",
    "println(\"Matrice de corrélation :\")\n",
    "\n",
    "# PLOT\n",
    "(n,m) = size(M)\n",
    "heatmap(M, fc=cgrad([:white,:dodgerblue4]), xticks=(1:m,numeric_cols), xrot=90, yticks=(1:m,numeric_cols), yflip=true)\n",
    "annotate!([(j, i, text(round(M[i,j],digits=3), 8,\"Computer Modern\",:black)) for i in 1:n for j in 1:m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette dernière matrice témoigne de plusieurs relations qui avaient été observées dans la section précédente. Effectivement, nous observons que le nombre de cylindres et la cylindrée sont fortement corrélés à la consommation, avec des valeurs de 0.857 et 0.853 respectivement. De plus, tel qu'attendu, la corrélation entre ces deux variables explicatives est très élevée avec une valeur 0.946. C'était attendu, car calcule la cylindrée d'un moteur avec $Cylindrée = Nombre de Cylindres * Volume$. Cela dit, nous allons devoir faire un choix dans la manière dont nous utiliserons celles-ci, comme l'ajout des deux variables ne présente pas d'avantage en terme d'information ajoutée. Cela donnerait un modèle avec de la multicolinéarité et choisir une des deux suffirait. Idéalement, nous opterons pour la variable la moins redondante tout en conservant une forte capacité prédiuctive. Nous pourrions évaluer les différentes performances avec les critères de sélection de modèle tel que le coefficient de détermination ajusté ou le critère d'information bayésien tout en minimisant le RMSE. En ce qui cocnerne la varaible année, elle est faiblement corrélée avec les autres variables explicatives et à la consommation du véhicule, ce qui confirme nos observations précédentes. La seule nouvelle information que nous pouvons tirer cette observation est que les vaiances de la consommation d'essence, du nombre de cylindres et de la cylindrée ont tendance à diminuer avec le temps, mais cela ne semble pas être une information pertinente pour notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prétraitement\n",
    "\n",
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Drop missing values in all datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "# # Encode 'boite' column in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new column with the grouped categories\n",
    "# # if transmission is 4x4, change for integrale\n",
    "# train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)\n",
    "# train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:type, :transmission, :boite]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "function standardizer(X, means, stds)\n",
    "    X = deepcopy(X)\n",
    "    for j in 1:size(X, 2)\n",
    "        if j in numeric_indices\n",
    "            X[:, j] = (X[:, j] .- means[j]) ./ stds[j]\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "# cols_to_normalize = [:age, :capacite_moteur]\n",
    "\n",
    "# means = [mean(train[!, col]) for col in cols_to_normalize]\n",
    "# stds = [std(train[!, col]) for col in cols_to_normalize]\n",
    "\n",
    "# train[!, cols_to_normalize] = standardizer(Matrix(train[!, cols_to_normalize]), means, stds)\n",
    "# valid[!, cols_to_normalize] = standardizer(Matrix(valid[!, cols_to_normalize]), means, stds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print every column in the dataframe\n",
    "\n",
    "rename!(train, \"boite_0.0\" => \"boite_0\", \"boite_1.0\" => \"boite_1\")\n",
    "rename!(valid, \"boite_0.0\" => \"boite_0\", \"boite_1.0\" => \"boite_1\")\n",
    "\n",
    "\n",
    "for col in names(train)\n",
    "    println(col)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de trouver le modèle qui offre le meilleur ajustement aux données tout en gardant une certaine simplicité. L'utilisation du BIC a été considéré afin d'en analyser les résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLM\n",
    "\n",
    "# Define all formulas for models\n",
    "model_formulas = [\n",
    "    @formula(consommation ~ age),\n",
    "    @formula(consommation ~ age + nombre_cylindres),\n",
    "    @formula(consommation ~ age + cylindree),\n",
    "    @formula(consommation ~ age + nombre_cylindres + cylindree ),\n",
    "    @formula(consommation ~ age + transmission_integrale),\n",
    "    @formula(consommation ~ age + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + nombre_cylindres),\n",
    "    @formula(consommation ~ age + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + cylindree),\n",
    "    @formula(consommation ~ age + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + cylindree + nombre_cylindres),\n",
    "    @formula(consommation ~ nombre_cylindres + cylindree + age + \n",
    "    type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte +\n",
    "    type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard +\n",
    "    transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + boite_0 + boite_1),\n",
    "    @formula(consommation ~ age + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + cylindree + type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte +\n",
    "    type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard),\n",
    "    @formula(consommation ~ age + cylindree + type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte +\n",
    "    type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard)\n",
    "]\n",
    "\n",
    "# Fit each model and calculate BIC\n",
    "# Fit models and calculate BIC\n",
    "models = []\n",
    "bics = []\n",
    "rmses = []\n",
    "for formula in model_formulas\n",
    "    model = lm(formula, train)\n",
    "    push!(models, model)\n",
    "    push!(bics, GLM.bic(model))\n",
    "    \n",
    "    # Calculate RMSE on validation set\n",
    "    valid_prediction = GLM.predict(model, valid)\n",
    "    rmse = sqrt(mean((valid_prediction - valid.consommation).^2))\n",
    "    push!(rmses, rmse)\n",
    "end\n",
    "\n",
    "# Find the best model by BIC and RMSE\n",
    "best_bic_index = argmin(bics)\n",
    "best_rmse_index = argmin(rmses)\n",
    "\n",
    "println(\"Best Model by BIC: \", model_formulas[best_bic_index])\n",
    "println(\"BIC: \", bics[best_bic_index])\n",
    "println(\"Best Model by RMSE: \", model_formulas[best_rmse_index])\n",
    "println(\"RMSE: \", rmses[best_rmse_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle linéaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(consommation ~ age + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + cylindree), train)\n",
    "#model = lm(@formula(consommation ~ age + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + nombre_cylindres), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction avec l'ensemble de validation\n",
    "valid_prediction = GLM.predict(model, valid)\n",
    "# Trouver la moyenne de prediction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "# Remplacer les missing par la moyenne\n",
    "#valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "# Transformer les predictions en valeur entiere\n",
    "#v = Int.(round.(valid_prediction, digits=0)) #mettre une commentaire sur la difference que ca entraine sur le rmse\n",
    "# Calculer le RMSE\n",
    "rmse_valid = sqrt(mean((valid_prediction - valid.consommation).^2))\n",
    "println(\"RMSE: \", rmse_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = nrow(test)\n",
    "\n",
    "id = 1:n\n",
    "\n",
    "ŷ = GLM.predict(model, test)\n",
    "\n",
    "df_pred = DataFrame(id=id, consommation=ŷ)\n",
    "\n",
    "name = \"linear/\" * string(rmse_valid) * \".csv\"\n",
    "CSV.write(\"../submissions/\" * name, df_pred)\n",
    "println(\"Predictions exported successfully to \" * name*\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Plots, StatsBase, StatsPlots, Random, StatsModels, GLM, LinearAlgebra, MultivariateStats, Distributions\n",
    "\n",
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "function safe_parse_float(x)\n",
    "    try\n",
    "        return parse(Float64, x)\n",
    "    catch\n",
    "        return missing\n",
    "    end\n",
    "end\n",
    "\n",
    "function one_hot_encode(df, cols, levels_dict)\n",
    "    for col in cols\n",
    "        levels_col = levels_dict[col]\n",
    "        for level in levels_col\n",
    "            new_col = Symbol(string(col) * \"_\" * string(level))\n",
    "            df[!, new_col] = ifelse.(df[!, col] .== level, 1.0, 0.0)\n",
    "        end\n",
    "        select!(df, Not(col))\n",
    "    end\n",
    "    return df\n",
    "end\n",
    "\n",
    "# ## convert annee column into age\n",
    "# train.age = 2024 .- train.annee\n",
    "# valid.age = 2024 .- valid.annee\n",
    "# test.age = 2024 .- test.annee\n",
    "\n",
    "# train = select!(train, Not(:annee))\n",
    "# valid = select!(valid, Not(:annee))\n",
    "# test = select!(test, Not(:annee))\n",
    "\n",
    "## drop missing values\n",
    "train = dropmissing(train)\n",
    "valid = dropmissing(valid)\n",
    "test = dropmissing(test)\n",
    "\n",
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Drop missing values in all datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "# Encode 'boite' column in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "end\n",
    "\n",
    "# train.cylindree = log.(train.cylindree .+ 1)\n",
    "# valid.cylindree = log.(valid.cylindree.+ 1)\n",
    "# test.cylindree = log.(test.cylindree.+ 1)\n",
    "\n",
    "function remove_outliers_by_iqr(df, group_col, value_col)\n",
    "    return combine(groupby(df, group_col)) do sdf\n",
    "        q1 = quantile(sdf[!, value_col], 0.25)\n",
    "        q3 = quantile(sdf[!, value_col], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        filter(row -> lower_bound ≤ row[value_col] ≤ upper_bound, sdf)\n",
    "    end\n",
    "end\n",
    "#Remove outliers in the training set\n",
    "train = remove_outliers_by_iqr(train, :cylindree, :consommation)\n",
    "valid = remove_outliers_by_iqr(valid, :cylindree, :consommation)\n",
    "\n",
    "# if transmission is 4x4, change for integrale\n",
    "train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)\n",
    "valid.transmission = ifelse.(valid.transmission .== \"4x4\", \"integrale\", valid.transmission)\n",
    "test.transmission = ifelse.(test.transmission .== \"4x4\", \"integrale\", test.transmission)\n",
    "\n",
    "train.transmission = ifelse.(train.transmission .== \"propulsion\", \"integrale\", train.transmission)\n",
    "valid.transmission = ifelse.(valid.transmission .== \"propulsion\", \"integrale\", valid.transmission)\n",
    "test.transmission = ifelse.(test.transmission .== \"propulsion\", \" integale\", test.transmission)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:type, :transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "#standardize the data\n",
    "mean_train = mean(train[!, :cylindree])\n",
    "std_train = std(train[!, :cylindree])\n",
    "\n",
    "train[!, :cylindree] = (train[!, :cylindree] .- mean_train) ./ std_train\n",
    "valid[!, :cylindree] = (valid[!, :cylindree] .- mean_train) ./ std_train\n",
    "test[!, :cylindree] = (test[!, :cylindree] .- mean_train) ./ std_train\n",
    "\n",
    "# mean_train = mean(train[!, :age])\n",
    "# std_train = std(train[!, :age])\n",
    "\n",
    "# train[!, :age] = (train[!, :age] .- mean_train) ./ std_train\n",
    "# valid[!, :age] = (valid[!, :age] .- mean_train) ./ std_train\n",
    "# test[!, :age] = (test[!, :age] .- mean_train) ./ std_train\n",
    "\n",
    "mean_train = mean(train[!, :consommation])\n",
    "std_train = std(train[!, :consommation])\n",
    "\n",
    "train[!, :consommation] = (train[!, :consommation] .- mean_train) ./ std_train\n",
    "valid[!, :consommation] = (valid[!, :consommation] .- mean_train) ./ std_train\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)\n",
    "\n",
    "# Define the target variable\n",
    "target = :consommation\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X_train = Matrix(train[:, Not([target])])\n",
    "y_train = train[!, target]\n",
    "X_valid = Matrix(valid[:, Not([target])])\n",
    "y_valid = valid[!, target]\n",
    "X_test = Matrix(test)\n",
    "\n",
    "# Define the model\n",
    "# model = lm(@formula(consommation ~ age + transmission_4x4+ transmission_integrale + transmission_propulsion + transmission_traction + boite + cylindree), train)\n",
    "model = lm(@formula(consommation ~  transmission_integrale + transmission_traction + boite + cylindree), train) #Meilleur\n",
    "# model = lm(@formula(consommation ~ age +  transmission_integrale + transmission_4x4 + transmission_traction + boite + cylindree), train)\n",
    "\n",
    "#model information\n",
    "println(model)\n",
    "\n",
    "#cross validation\n",
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.consommation\n",
    "X = select(data_k_folds, Not(:consommation))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 5\n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    valid_indices = (i * fold_size + 1):((i + 1) * fold_size)\n",
    "    train_indices = setdiff(1:n, valid_indices)\n",
    "    \n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_valid = X[valid_indices, :]\n",
    "    y_valid = y[valid_indices]\n",
    "    \n",
    "    df = DataFrame(X_train)\n",
    "    df.consommation = y_train\n",
    "\n",
    " model = lm(@formula(consommation ~ transmission_traction + boite + cylindree), df) #Meilleur\n",
    "    \n",
    "    ŷ_valid = GLM.predict(model, X_valid)\n",
    "    rms = sqrt(mean((ŷ_valid .- y_valid).^2))\n",
    "    push!(rms_scores, rms)\n",
    "end\n",
    "\n",
    "moyenne_rmse = mean(rms_scores)\n",
    "std_consommation = std(data_k_folds.consommation)\n",
    "\n",
    "real_rmse = moyenne_rmse * std_train\n",
    "println(\"Moyenne RMSE k-fold : $real_rmse\")\n",
    "\n",
    "# Make predictions\n",
    "ŷ_train = GLM.predict(model, train)\n",
    "ŷ_valid = GLM.predict(model, valid)\n",
    "\n",
    "vif_values = vif(model)\n",
    "println(\"VIF values: \", vif_values)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_train = sqrt(mean((ŷ_train .- train.consommation).^2))\n",
    "rmse_valid = sqrt(mean((ŷ_valid .- valid.consommation).^2))\n",
    "\n",
    "#plot dirstribtuion of residuals\n",
    "res = ŷ_valid .- valid.consommation\n",
    "h = histogram(res, bins=50, title=\"Distribution of res\", xlabel=\"res\", ylabel=\"Frequency\")\n",
    "display(h)\n",
    "\n",
    "# # extreme values\n",
    "# extreme_values = valid[abs.(res) .> 2, [:cylindree, :consommation, :transmission_integrale, :transmission_traction, :boite]]\n",
    "# println(extreme_values)\n",
    "\n",
    "# # find the row with the highest residual\n",
    "# max_residual_index = argmax(abs.(res))\n",
    "# max_residual_row = valid[max_residual_index, :]\n",
    "# println(max_residual_row)\n",
    "\n",
    "println(\"RMSE train: \", rmse_train * std_train)\n",
    "println(\"RMSE valid: \", rmse_valid * std_train)\n",
    "\n",
    "\n",
    "scatter(train[!, :cylindree], res,\n",
    "        xlabel=\"Cylindrée\", ylabel=\"Résidus\",\n",
    "        title=\"Résidus vs Cylindrée\")\n",
    "println(\"mean res: \", mean(res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Régression bayesienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert annee column into age\n",
    "train.age = 2024 .- train.annee\n",
    "valid.age = 2024 .- valid.annee\n",
    "test.age = 2024 .- test.annee\n",
    "\n",
    "train = select!(train, Not(:annee))\n",
    "valid = select!(valid, Not(:annee))\n",
    "test = select!(test, Not(:annee))\n",
    "\n",
    "## drop missing values\n",
    "train = dropmissing(train)\n",
    "valid = dropmissing(valid)\n",
    "test = dropmissing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Drop missing values in all datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "# # Encode 'boite' column in all datasets\n",
    "# for df in [train, valid, test]\n",
    "#     df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:type, :transmission, :boite]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.consommation\n",
    "X_train = select(train, Not(:consommation))\n",
    "y_valid = valid.consommation\n",
    "X_valid = select(valid, Not(:consommation))\n",
    "X_test = deepcopy(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric feature indices\n",
    "feature_names = names(train)\n",
    "numeric_features = [ :cylindree, :nombre_cylindres, :age]\n",
    "numeric_indices = findall(x -> x in numeric_features, feature_names)\n",
    "\n",
    "means = mean(Matrix(X_train[:, numeric_features]), dims=1)\n",
    "stds = std(Matrix(X_train[:, numeric_features]), dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standardizer(X, means, stds)\n",
    "    X = deepcopy(X)\n",
    "    for j in 1:size(X, 2)\n",
    "        if j in numeric_indices\n",
    "            X[:, j] = (X[:, j] .- means[j]) ./ stds[j]\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = standardizer(Matrix(X_train), means, stds)\n",
    "X_valid = standardizer(Matrix(X_valid), means, stds)\n",
    "X_test = standardizer(Matrix(X_test), means, stds)\n",
    "\n",
    "y_train = Vector(y_train)\n",
    "y_valid = Vector(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with cross-validation\n",
    "XtX = X_train' * X_train\n",
    "Xty = X_train' * y_train\n",
    "n_features = size(X_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = 10 .^ range(-5, stop=5, length=1000)\n",
    "best_rmse = Inf\n",
    "best_lambda = 0.0\n",
    "best_beta = nothing\n",
    "\n",
    "\n",
    "for λ in lambda_values\n",
    "    beta = (XtX + λ * I) \\ Xty\n",
    "    y_pred_valid = X_valid * beta\n",
    "    rmse = sqrt(mean((y_pred_valid - y_valid).^2))\n",
    "    if rmse < best_rmse\n",
    "        best_rmse = rmse\n",
    "        best_lambda = λ\n",
    "        best_beta = beta\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Best Lambda: \", best_lambda)\n",
    "println(\"Best RMSE: \", best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation on validation set\n",
    "y_valid_pred = X_valid * best_beta\n",
    "rmse_valid = sqrt(mean((y_valid_pred - y_valid).^2))\n",
    "println(\"Validation RMSE: \", rmse_valid)\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_pred = X_test * best_beta\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "n_test = size(y_test_pred, 1)\n",
    "id = 1:n_test\n",
    "df_pred = DataFrame(id=id, consommation=y_test_pred)\n",
    "\n",
    "name = \"ridge\" * string(rmse_valid) * \".csv\"\n",
    "CSV.write(\"../submissions/bayes/\" * name, df_pred)\n",
    "println(\"Predictions exported successfully to \" * name*\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation par k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.consommation\n",
    "X = select(data_k_folds, Not(:consommation))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 5  \n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    test_indices = indices[(i*fold_size + 1):min((i+1)*fold_size, n)]\n",
    "    train_indices = setdiff(indices, test_indices)\n",
    "    \n",
    "    train_data = data_k_folds[train_indices, :]\n",
    "    test_data = data_k_folds[test_indices, :]\n",
    "    \n",
    "    model = lm(@formula(consommation ~ age  + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + cylindree), data_k_folds)\n",
    " \n",
    "    \n",
    "    valid_prediction = GLM.predict(model, test_data)\n",
    "    \n",
    "    mean_prediction = mean(skipmissing(valid_prediction))\n",
    "    valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "    \n",
    "    if any(ismissing, valid_prediction)\n",
    "        error(\"Skip les valeur missing\")\n",
    "    end\n",
    "    \n",
    "    v = max.(valid_prediction, 0) \n",
    "    \n",
    "    score = sqrt(mean((v - test_data.consommation).^2))\n",
    "    push!(rms_scores, score)\n",
    "end\n",
    "\n",
    "moyenne_rmse = mean(rms_scores)\n",
    "println(\"Moyenne RMSE : $moyenne_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "using MultivariateStats\n",
    "using GLM\n",
    "\n",
    "# Data Cleaning and Preparation\n",
    "Random.seed!(1234) # For reproducibility\n",
    "\n",
    "# Split the data\n",
    "ntrain = round(Int, 0.8 * nrow(full_train))\n",
    "train_id = sample(1:nrow(full_train), ntrain; replace=false, ordered=true)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "train = full_train[train_id, :]\n",
    "valid = full_train[valid_id, :]\n",
    "train = full_train\n",
    "\n",
    "# Data cleaning\n",
    "for col in [:cylindree, :consommation]\n",
    "    train[!, col] = replace.(train[!, col], \",\" => \".\")\n",
    "    valid[!, col] = replace.(valid[!, col], \",\" => \".\")\n",
    "    train[!, col] = safe_parse_float.(train[!, col])\n",
    "    valid[!, col] = safe_parse_float.(valid[!, col])\n",
    "end\n",
    "\n",
    "for col in [:cylindree,]\n",
    "    test[!, col] = replace.(test[!, col], \",\" => \".\")\n",
    "    test[!, col] = safe_parse_float.(test[!, col])\n",
    "end\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:type, :transmission, :boite]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "# levels_dict = Dict()\n",
    "# for col in categorical_cols\n",
    "#     levels_dict[col] = unique(train[!, col])\n",
    "# end\n",
    "\n",
    "#train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "#valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "#test = one_hot_encode(test, categorical_cols, levels_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Plots\n",
    "\n",
    "# Extraire les variables continues\n",
    "continuous_vars = train[:, [:cylindree, :nombre_cylindres, :consommation]]\n",
    "\n",
    "# Convertir en matrice et calculer la corrélation\n",
    "data_matrix = Matrix(continuous_vars)\n",
    "correlation_matrix = cor(data_matrix)\n",
    "\n",
    "# Afficher la matrice\n",
    "println(\"Matrice de corrélation :\")\n",
    "println(correlation_matrix)\n",
    "\n",
    "# Visualiser la matrice\n",
    "heatmap(correlation_matrix,\n",
    "    xticks = (1:size(correlation_matrix, 1), names(continuous_vars)),\n",
    "    yticks = (1:size(correlation_matrix, 2), names(continuous_vars)),\n",
    "    title = \"Matrice de corrélation\",\n",
    "    color = :coolwarm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "# Calcul des moyennes de consommation par catégorie pour 'type'\n",
    "mean_values = combine(groupby(train, :transmission), :consommation => mean => :mean_consommation)\n",
    "println(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsPlots\n",
    "\n",
    "@df mean_values bar(:transmission, :mean_consommation, xlabel=\"Type de véhicule\", ylabel=\"Consommation Moyenne\", title=\"Consommation Moyenne par transmission\", legend=false, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "# Calcul des moyennes de consommation par catégorie pour 'type'\n",
    "mean_values = combine(groupby(train, :boite), :consommation => mean => :mean_consommation)\n",
    "println(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsPlots\n",
    "\n",
    "@df mean_values bar(:boite, :mean_consommation, xlabel=\"Type de véhicule\", ylabel=\"Consommation Moyenne\", title=\"Consommation Moyenne par boite\", legend=false, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CategoricalArrays\n",
    "\n",
    "train.categorie_vehicule = CategoricalArray{String}(undef, nrow(train))\n",
    "\n",
    "for i in 1:nrow(train)\n",
    "    if train.type[i] in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        train.categorie_vehicule[i] = \"Petits Véhicules\"\n",
    "    elseif train.type[i] in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        train.categorie_vehicule[i] = \"Véhicules Moyens\"\n",
    "    else\n",
    "        train.categorie_vehicule[i] = \"Grands Véhicules\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"HypothesisTests\")\n",
    "\n",
    "using StatsModels, GLM, HypothesisTests\n",
    "\n",
    "# Ajuster le modèle complet\n",
    "model_full = lm(@formula(consommation ~ categorie_vehicule), train)\n",
    "\n",
    "# Ajuster le modèle réduit\n",
    "model_reduced = lm(@formula(consommation ~ 1), train)\n",
    "\n",
    "# Effectuer le test F\n",
    "ftest_result = ftest(model_full.model, model_reduced.model)\n",
    "println(ftest_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_transmission(transmission)\n",
    "    if transmission in [\"integrale\", \"4x4\", \"propulsion\"]\n",
    "        return \"AWD/RWD\"\n",
    "    else\n",
    "        return \"traction\"\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour le DataFrame 'train'\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'valid'\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'test'\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:, :categorie_transmission] = [categorize_transmission(t) for t in train[:, :transmission]]\n",
    "valid[:, :categorie_transmission] = [categorize_transmission(t) for t in valid[:, :transmission]]\n",
    "test[:, :categorie_transmission] = [categorize_transmission(t) for t in test[:, :transmission]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, Statistics\n",
    "\n",
    "# Data cleaning\n",
    "for col in [:consommation]\n",
    "    train[!, col] = replace.(train[!, col], \",\" => \".\")\n",
    "    valid[!, col] = replace.(valid[!, col], \",\" => \".\")\n",
    "    train[!, col] = safe_parse_float.(train[!, col])\n",
    "    valid[!, col] = safe_parse_float.(valid[!, col])\n",
    "end\n",
    "\n",
    "# Calculer la consommation moyenne par combinaison de categorie_vehicule et categorie_transmission\n",
    "mean_consumption_interaction = combine(groupby(train, [:categorie_vehicule, :categorie_transmission]),\n",
    "                                      :consommation => mean => :mean_consommation)\n",
    "\n",
    "println(mean_consumption_interaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Plots, StatsBase, StatsPlots, Random, StatsModels, GLM, LinearAlgebra, MultivariateStats, Distributions\n",
    "\n",
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "function safe_parse_float(x)\n",
    "    try\n",
    "        return parse(Float64, x)\n",
    "    catch\n",
    "        return missing\n",
    "    end\n",
    "end\n",
    "\n",
    "function one_hot_encode(df, cols, levels_dict)\n",
    "    for col in cols\n",
    "        levels_col = levels_dict[col]\n",
    "        for level in levels_col\n",
    "            new_col = Symbol(string(col) * \"_\" * string(level))\n",
    "            df[!, new_col] = ifelse.(df[!, col] .== level, 1.0, 0.0)\n",
    "        end\n",
    "        select!(df, Not(col))\n",
    "    end\n",
    "    return df\n",
    "end\n",
    "\n",
    "## convert annee column into age\n",
    "train.age = 2024 .- train.annee\n",
    "valid.age = 2024 .- valid.annee\n",
    "test.age = 2024 .- test.annee\n",
    "\n",
    "train = select!(train, Not(:annee))\n",
    "valid = select!(valid, Not(:annee))\n",
    "test = select!(test, Not(:annee))\n",
    "\n",
    "## drop missing values\n",
    "train = dropmissing(train)\n",
    "valid = dropmissing(valid)\n",
    "test = dropmissing(test)\n",
    "\n",
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Drop missing values in all datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "# Encode 'boite' column in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "end\n",
    "\n",
    "train.cylindree = log.(train.cylindree .+ 1)\n",
    "valid.cylindree = log.(valid.cylindree.+ 1)\n",
    "test.cylindree = log.(test.cylindree.+ 1)\n",
    "\n",
    "function remove_outliers_by_iqr(df, group_col, value_col)\n",
    "    return combine(groupby(df, group_col)) do sdf\n",
    "        q1 = quantile(sdf[!, value_col], 0.25)\n",
    "        q3 = quantile(sdf[!, value_col], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        filter(row -> lower_bound ≤ row[value_col] ≤ upper_bound, sdf)\n",
    "    end\n",
    "end\n",
    "#Remove outliers in the training set\n",
    "train = remove_outliers_by_iqr(train, :cylindree, :consommation)\n",
    "valid = remove_outliers_by_iqr(valid, :cylindree, :consommation)\n",
    "\n",
    "# # change type break_petit to voiture_minicompacte\n",
    "# train.type = replace(train.type, \"break_petit\" => \"voiture_minicompacte\")\n",
    "# valid.type = replace(valid.type, \"break_petit\" => \"voiture_minicompacte\")\n",
    "# test.type = replace(test.type, \"break_petit\" => \"voiture_minicompacte\")\n",
    "\n",
    "# if transmission is 4x4, change for integrale\n",
    "# train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)\n",
    "# valid.transmission = ifelse.(valid.transmission .== \"4x4\", \"integrale\", valid.transmission)\n",
    "# test.transmission = ifelse.(test.transmission .== \"4x4\", \"integrale\", test.transmission)\n",
    "function categorize_transmission(transmission)\n",
    "    if transmission in [\"integrale\", \"4x4\", \"propulsion\"]\n",
    "        return \"AWDRWD\"\n",
    "    else\n",
    "        return \"traction\"\n",
    "    end\n",
    "end\n",
    "\n",
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "train[:, :categorie_transmission] = [categorize_transmission(t) for t in train[:, :transmission]]\n",
    "valid[:, :categorie_transmission] = [categorize_transmission(t) for t in valid[:, :transmission]]\n",
    "test[:, :categorie_transmission] = [categorize_transmission(t) for t in test[:, :transmission]]\n",
    "\n",
    "\n",
    "\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]\n",
    "\n",
    "\n",
    "train = select!(train, Not(:transmission, :type))\n",
    "valid = select!(valid, Not(:transmission, :type))\n",
    "test = select!(test, Not(:transmission, :type))\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:categorie_vehicule, :categorie_transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)\n",
    "\n",
    "\n",
    "# Define the target variable\n",
    "target = :consommation\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X_train = Matrix(train[:, Not([target])])\n",
    "y_train = train[!, target]\n",
    "X_valid = Matrix(valid[:, Not([target])])\n",
    "y_valid = valid[!, target]\n",
    "X_test = Matrix(test)\n",
    "\n",
    "# Create interaction terms\n",
    "train.categorie_transmission_traction_vehicule_petits = train.categorie_transmission_traction .* train.categorie_vehicule_petits_véhicules\n",
    "train.categorie_transmission_traction_vehicule_moyens = train.categorie_transmission_traction .* train.categorie_vehicule_véhicules_moyens\n",
    "\n",
    "valid.categorie_transmission_traction_vehicule_petits = valid.categorie_transmission_traction .* valid.categorie_vehicule_petits_véhicules\n",
    "valid.categorie_transmission_traction_vehicule_moyens = valid.categorie_transmission_traction .* valid.categorie_vehicule_véhicules_moyens\n",
    "\n",
    "test.categorie_transmission_traction_vehicule_petits = test.categorie_transmission_traction .* test.categorie_vehicule_petits_véhicules\n",
    "test.categorie_transmission_traction_vehicule_moyens = test.categorie_transmission_traction .* test.categorie_vehicule_véhicules_moyens\n",
    "\n",
    "\n",
    "# Define the model\n",
    "# model = lm(@formula(consommation ~ age + transmission_4x4+ transmission_integrale + transmission_propulsion + transmission_traction + boite + cylindree), train)\n",
    "model = lm(@formula(consommation ~ age + categorie_transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_véhicules_moyens + boite + cylindree), train) #Meilleur\n",
    "# model = lm(@formula(consommation ~ age +  transmission_integrale + transmission_4x4 + transmission_traction + boite + cylindree), train)\n",
    "println(model)\n",
    "#cross validation\n",
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.consommation\n",
    "X = select(data_k_folds, Not(:consommation))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 5\n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    valid_indices = (i * fold_size + 1):((i + 1) * fold_size)\n",
    "    train_indices = setdiff(1:n, valid_indices)\n",
    "    \n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_valid = X[valid_indices, :]\n",
    "    y_valid = y[valid_indices]\n",
    "    \n",
    "# model = lm(@formula(consommation ~ age + categorie_transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_véhicules_moyens + boite + cylindree), train) #Meilleur\n",
    " model = lm(@formula(consommation ~ age + categorie_transmission_traction + boite + cylindree), train) #Meilleur\n",
    "    \n",
    "    ŷ_valid = GLM.predict(model, X_valid)\n",
    "    rms = sqrt(mean((ŷ_valid .- y_valid).^2))\n",
    "    push!(rms_scores, rms)\n",
    "end\n",
    "\n",
    "moyenne_rmse = mean(rms_scores)\n",
    "println(\"Moyenne RMSE k-fold : $moyenne_rmse\")\n",
    "\n",
    "# Make predictions\n",
    "ŷ_train = GLM.predict(model, train)\n",
    "ŷ_valid = GLM.predict(model, valid)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_train = sqrt(mean((ŷ_train .- train.consommation).^2))\n",
    "rmse_valid = sqrt(mean((ŷ_valid .- valid.consommation).^2))\n",
    "\n",
    "println(\"RMSE on the training set: $rmse_train\")\n",
    "println(\"RMSE on the validation set: $rmse_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dirstribtuion of residuals\n",
    "residuals = ŷ_valid .- valid.consommation\n",
    "h = histogram(residuals, bins=50, title=\"Distribution of residuals\", xlabel=\"Residuals\", ylabel=\"Frequency\")\n",
    "println(mean(residuals)) \n",
    "display(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Régression par l'approche des composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TODO CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MultivariateStats\n",
    "using GLM\n",
    "\n",
    "# Data Cleaning and Preparation\n",
    "Random.seed!(1234) # For reproducibility\n",
    "\n",
    "# Split the data\n",
    "ntrain = round(Int, 0.8 * nrow(full_train))\n",
    "train_id = sample(1:nrow(full_train), ntrain; replace=false, ordered=true)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "train = full_train[train_id, :]\n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "\n",
    "# Pour le DataFrame 'train'\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'valid'\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'test'\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]\n",
    "\n",
    "# Créer la variable 'categorie_transmission' dans les trois DataFrames\n",
    "train[:, :categorie_transmission] = [categorize_transmission(t) for t in train[:, :transmission]]\n",
    "valid[:, :categorie_transmission] = [categorize_transmission(t) for t in valid[:, :transmission]]\n",
    "test[:, :categorie_transmission] = [categorize_transmission(t) for t in test[:, :transmission]]\n",
    "\n",
    "\n",
    "\n",
    "# remove type column\n",
    "train = select!(train, Not(:transmission, :type))\n",
    "valid = select!(valid, Not(:transmission, :type))\n",
    "test = select!(test, Not(:transmission, :type))\n",
    "\n",
    "\n",
    "# Data cleaning\n",
    "for col in [:cylindree, :consommation]\n",
    "    train[!, col] = replace.(train[!, col], \",\" => \".\")\n",
    "    valid[!, col] = replace.(valid[!, col], \",\" => \".\")\n",
    "    train[!, col] = safe_parse_float.(train[!, col])\n",
    "    valid[!, col] = safe_parse_float.(valid[!, col])\n",
    "end\n",
    "\n",
    "for col in [:cylindree,]\n",
    "    test[!, col] = replace.(test[!, col], \",\" => \".\")\n",
    "    test[!, col] = safe_parse_float.(test[!, col])\n",
    "end\n",
    "\n",
    "train.cylindree = log.(train.cylindree .+ 1)\n",
    "valid.cylindree = log.(valid.cylindree.+ 1)\n",
    "test.cylindree = log.(test.cylindree.+ 1)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:categorie_vehicule, :categorie_transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns\n",
    "numeric_cols = setdiff(names(train)[eltype.(eachcol(train)) .<: Real], [\"consommation\"])\n",
    "\n",
    "println(\"Numeric columns: \", numeric_cols)\n",
    "\n",
    "# Extract numeric columns\n",
    "X_train = Matrix(select(train, numeric_cols))\n",
    "y_train = Vector(train.consommation)\n",
    "X_valid = Matrix(select(valid, numeric_cols))\n",
    "\n",
    "# Standardize the data (commented out)\n",
    "# X_mean = mean(X_train; dims=1)\n",
    "# X_stddev = std(X_train; dims=1, corrected=false)\n",
    "# X_train_std = (X_train .- X_mean) ./ X_stddev\n",
    "# X_valid_std = (X_valid .- X_mean) ./ X_stddev\n",
    "\n",
    "# Perform PCA\n",
    "pca_model = fit(PCA, X_train'; maxoutdim=5)  # Use original data without standardization\n",
    "Z_train = MultivariateStats.transform(pca_model, X_train')'\n",
    "Z_valid = MultivariateStats.transform(pca_model, X_valid')'\n",
    "\n",
    "# Add principal components to DataFrames (train and valid)\n",
    "for i in 1:size(Z_train, 2)\n",
    "    train[:, \"PC$(i)\"] = Z_train[:, i]\n",
    "    valid[:, \"PC$(i)\"] = Z_valid[:, i]\n",
    "end\n",
    "\n",
    "# Fit a regression model using PCA\n",
    "model_with_pca = lm(@formula(consommation ~ PC1 + PC2 + PC3 + PC4 + PC5), train)\n",
    "\n",
    "# Predict on validation data\n",
    "valid_prediction_with_pca = predict(model_with_pca, valid)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_with_pca = sqrt(mean((valid_prediction_with_pca - valid.consommation).^2))\n",
    "println(\"RMSE with PCA: \", rmse_with_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x̄ = vec(mean(X, dims=1))\n",
    "\n",
    "Z = X .- x̄'\n",
    "\n",
    "F = svd(Z)\n",
    "V = F.V\n",
    "U = F.U\n",
    "γ = F.S;\n",
    "\n",
    "cumvar = cumsum(γ.^2)\n",
    "\n",
    "ratio = cumvar / cumvar[end]\n",
    "\n",
    "df = DataFrame(k = Int64[], Variance = Float64[])\n",
    "\n",
    "for k in 1:length(ratio)\n",
    "    push!(df, [k, ratio[k]])\n",
    "end\n",
    "\n",
    "Gadfly.plot(df, x=:k, y=:Variance, Geom.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Impact des échelles dans les données\n",
    "Dans les données non standardisées, les variables explicatives ayant des valeurs plus grandes peuvent dominer la variance totale, ce qui oriente la PCA vers ces variables. Si ces variables sont fortement corrélées avec la variable cible (\n",
    "𝑌\n",
    "Y), alors le modèle peut accidentellement mieux capturer cette relation.\n",
    "En revanche, la standardisation neutralise les différences d'échelle, ce qui peut diluer l'effet des variables dominantes, même si elles ont une forte corrélation avec \n",
    "𝑌\n",
    "Y.\n",
    "Explication potentielle :\n",
    "Dans votre jeu de données, il est possible qu'une ou plusieurs variables avec des échelles plus grandes soient prédictives de \n",
    "𝑌\n",
    "Y, et la méthode non standardisée en profite directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Sur-ajustement (Overfitting)\n",
    "La méthode non standardisée applique la PCA sur les données d'origine, mais utilise ensuite les données reconstruites (\n",
    "𝑋\n",
    "𝑟\n",
    "X \n",
    "r\n",
    "​\n",
    " ) pour l'entraînement. Cela peut réintroduire une grande partie des informations originales, y compris le bruit ou les corrélations spurielles, ce qui peut conduire à un modèle sur-ajusté.\n",
    "Si l'ensemble de validation est similaire à l'ensemble d'entraînement (par exemple, s'il provient de la même distribution ou a des caractéristiques similaires), un sur-ajustement peut donner des RMSE artificiellement bas.\n",
    "Explication potentielle :\n",
    "Votre validation pourrait être moins rigoureuse, et la méthode non standardisée exploite des relations non généralisables dans les données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Le fait que la méthode non standardisée donne un meilleur RMSE peut s'expliquer par plusieurs raisons, mais cela ne signifie pas nécessairement qu'elle est meilleure ou qu'elle respecte les principes statistiques sous-jacents. Explorons pourquoi cela pourrait se produire :\n",
    "\n",
    "1. Impact des échelles dans les données\n",
    "Dans les données non standardisées, les variables explicatives ayant des valeurs plus grandes peuvent dominer la variance totale, ce qui oriente la PCA vers ces variables. Si ces variables sont fortement corrélées avec la variable cible (\n",
    "𝑌\n",
    "Y), alors le modèle peut accidentellement mieux capturer cette relation.\n",
    "En revanche, la standardisation neutralise les différences d'échelle, ce qui peut diluer l'effet des variables dominantes, même si elles ont une forte corrélation avec \n",
    "𝑌\n",
    "Y.\n",
    "Explication potentielle :\n",
    "Dans votre jeu de données, il est possible qu'une ou plusieurs variables avec des échelles plus grandes soient prédictives de \n",
    "𝑌\n",
    "Y, et la méthode non standardisée en profite directement.\n",
    "\n",
    "2. Sur-ajustement (Overfitting)\n",
    "La méthode non standardisée applique la PCA sur les données d'origine, mais utilise ensuite les données reconstruites (\n",
    "𝑋\n",
    "𝑟\n",
    "X \n",
    "r\n",
    "​\n",
    " ) pour l'entraînement. Cela peut réintroduire une grande partie des informations originales, y compris le bruit ou les corrélations spurielles, ce qui peut conduire à un modèle sur-ajusté.\n",
    "Si l'ensemble de validation est similaire à l'ensemble d'entraînement (par exemple, s'il provient de la même distribution ou a des caractéristiques similaires), un sur-ajustement peut donner des RMSE artificiellement bas.\n",
    "Explication potentielle :\n",
    "Votre validation pourrait être moins rigoureuse, et la méthode non standardisée exploite des relations non généralisables dans les données.\n",
    "\n",
    "3. Corrélation forte entre les variables\n",
    "Si les variables explicatives ont une forte corrélation intrinsèque, l'analyse en composantes principales standardisée peut répartir cette information sur plusieurs composantes. Cela réduit la capacité du modèle à se concentrer sur des variables fortement corrélées avec \n",
    "𝑌\n",
    "Y.\n",
    "La méthode non standardisée, en revanche, conserve ces corrélations et peut donc mieux modéliser la relation entre \n",
    "𝑋\n",
    "X et \n",
    "𝑌\n",
    "Y.\n",
    "Explication potentielle :\n",
    "Les corrélations fortes dans vos données favorisent la méthode non standardisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Effet des données reconstruites\n",
    "Dans la méthode non standardisée, vous utilisez des données reconstruites (\n",
    "𝑋\n",
    "𝑟\n",
    "X \n",
    "r\n",
    "​\n",
    " ), qui incluent une grande partie de l'information originale. Cela signifie que la régression est moins influencée par la réduction de dimension et plus proche de la régression sur les données d'origine.\n",
    "En revanche, dans la méthode standardisée, seules les composantes principales sont utilisées, ce qui peut sacrifier une partie de l'information pour réduire la multicolinéarité et améliorer la généralisation.\n",
    "Explication potentielle :\n",
    "L'utilisation des données reconstruites dans la méthode non standardisée maintient plus d'information, ce qui peut donner un RMSE plus faible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Problème avec la PCA standardisée\n",
    "Si la standardisation n'est pas appropriée (par exemple, si certaines variables explicatives sont presque constantes ou si elles sont déjà sur des échelles comparables), alors l'analyse en composantes principales standardisée peut ne pas capturer efficacement les directions principales de la variance.\n",
    "Cela peut entraîner une perte d'information utile, ce qui affecte les performances du modèle.\n",
    "Explication potentielle :\n",
    "Les variables de votre jeu de données n'ont peut-être pas besoin d'être standardisées ou la standardisation introduit un biais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
