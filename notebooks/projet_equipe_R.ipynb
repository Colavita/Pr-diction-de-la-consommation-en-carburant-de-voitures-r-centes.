{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 - Méthodes probabilistes et statistiques pour I.A.\n",
    "#### Polytechnique Montréal\n",
    "\n",
    "\n",
    "### Projet A2024\n",
    "\n",
    "-----\n",
    "\n",
    "# Prédiction de la consommation en carburant de voitures récentes\n",
    "\n",
    "### Contexte\n",
    "\n",
    "Dans le cadre de ce projet, on nous fournit un jeu de données comprenant différentes caractéristiques de véhicules à essence ainsi que leur consommation d'essence en L/100km.\n",
    "\n",
    "### Objectif\n",
    "\n",
    "L'objectif du projet est de prédire, pour un ensemble de données de validation, la consommation d'essence d'un véhicule en se fiant à ses autres caractéristiques.  Pour ce faire, nous explorerons différentes avenues tant au niveau du traitement des données d'entraînement qu'au niveau de la conception d'un modèle. \n",
    "\n",
    "### Données\n",
    "\n",
    "Les données utilisées pour inférer la consommation de carburant sont les suivantes :\n",
    "\n",
    "- `train.csv` : données d'un ensemble d'entraînement qui comprennent différentes caractéristiques de véhicules et leur consommation d'essence associée \n",
    "- `test.csv` : données d'un ensemble de validation qui comprennent tout sauf la consommation d'essence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par importer les librairies nécessaires à l'utilisation de ce calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Plots, StatsBase, StatsPlots, Random, StatsModels, GLM, LinearAlgebra, MultivariateStats, Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite charger les données de l'ensemble d'entraînement et de l'ensemble de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") # ne contient pas la variable \"consommation\"\n",
    "\n",
    "Random.seed!(1234) # pour la reproductibilité\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) # 80% des données pour l'entraînement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) # échantillonnage aléatoire pour l'entraînement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) # échantillon de validation ; prend les données qui ne sont pas dans l'échantillon d'entraînement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(valid, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first(test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate donc que les données ont été bien chargées, et que l'ensemble de test comprend également une colonne de moins que l'ensemble full_train, soit la colonne de consommation d'essence.  De plus, nous avons séparé le jeu de données d'entraînement en deux sous-groupes : 80% pour l'entraînement dans la variable \"train\", et le 20% restant pour assurer la validation dans la variable \"valid\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour continuer, nous avons créé quelques fonctions génériques qui seront utiles à plusieurs reprises plus loin dans le calepin.  Afin d'éviter des répétitions inutiles de ces procédés, et pour s'assurer de pouvoir retracer ces fonctions rapidement, elles sont regroupées sous cette rubrique \"helpers\".\n",
    "\n",
    "D'abord, nous avons réalisé en affichant les données à la section précédente que deux données numériques, la cylindrée et la consommation, étaient en format String plutôt que d'un type Float. Naturellement, cette incohérence dans le jeu de données nous empêchera de travailler avec celles-ci, et c'est pourquoi nous nous sommes munis d'un outil de conversion en Float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function safe_parse_float(x)\n",
    "    try\n",
    "        return parse(Float64, x)\n",
    "    catch\n",
    "        return missing\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, pour les données non numériques comme le type de véhicule, la transmission et la boîte, nous devons nous munir d'une méthode de conversion pour encoder ces données de façon à ce que le modèle d'apprentissage automatique puissent les traiter adéquatement.  La méthode que nous avons choisie est l'encodage \"one-hot\", qui consiste à créer une nouvelle colonne pour chaque catégorie et à assigner la valeur 1 à cette colonne si c'est la rangée correspond à cette catégorie, et la valeur 0 dans tous les autres cas.  Nous avons choisi la méthode one-hot afin d'éviter les problèmes que l'autre méthode d'encodage populaire que nous considérions, l'encodage ordinal, peut poser, notamment les biais de magnitude (0 et 1 sont des valeurs neutres qui ne discriminent pas entre les catégories, contrairement aux valeurs ordinales 1, 2, 3, ... qui peuvent influencer les prédictions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_encode(df, cols, levels_dict)\n",
    "    for col in cols\n",
    "        levels_col = levels_dict[col]\n",
    "        for level in levels_col\n",
    "            new_col = Symbol(string(col) * \"_\" * string(level))\n",
    "            df[!, new_col] = ifelse.(df[!, col] .== level, 1.0, 0.0)\n",
    "        end\n",
    "        select!(df, Not(col))\n",
    "    end\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'accélérer le développement de notre solution, nous nous sommes également munis d'une fonction qui applique un pre-processing de base aux jeux de données pertinents.  Cette méthode commencer par remplacer les virgules par des points dans les colonnes numériques qui sont en String par défaut dans les jeux de données, puis applique la conversion en Float directement et retire les valeurs manquantes à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function default_prerocessing(data)\n",
    "\n",
    "# distinguer les jeux de données ayant la colonne \"consommation\" de ceux qui ne l'ont pas\n",
    "datasets_with_consommation = [data]\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# dans tous les jeux de données, remplacer les virgules par des points dans 'cylindree' pour pouvoir convertir en float ensuite\n",
    "for df in [data]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# idem pour les jeux de données ayant la colonne 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# convertir 'cylindree' en float dans tous les jeux de données\n",
    "for df in [data]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# convertir 'consommation' en float dans les jeux de données ayant la colonne 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# retirer les valeurs manquantes dans tous les jeux de données\n",
    "for df in [data]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function remove_outliers_by_iqr(df, group_col, value_col)\n",
    "    return combine(groupby(df, group_col)) do sdf\n",
    "        q1 = quantile(sdf[!, value_col], 0.25)\n",
    "        q3 = quantile(sdf[!, value_col], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        filter(row -> lower_bound ≤ row[value_col] ≤ upper_bound, sdf)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_raj(X, y, ŷ)\n",
    "    SSe = sum((ŷ .- y).^2)\n",
    "    SSt = sum((y .- mean(y)).^2)\n",
    "    n = size(y, 1)\n",
    "    p = size(X, 2)\n",
    "    return 1 - (SSe / (n - p - 1)) / (SSt / (n - 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_bic(X, model)\n",
    "    # Compute log-likelihood\n",
    "    log_likelihood = loglikelihood(model)\n",
    "\n",
    "    # Number of observations and parameters\n",
    "    n = size(X, 1)  # Number of observations\n",
    "    k = length(coef(model))  # Number of estimated parameters\n",
    "\n",
    "    # Compute BIC\n",
    "    bic = log_likelihood - (k/2) * log(n)\n",
    "\n",
    "    return bic # Return both BIC and the fitted model\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par nous familiariser avec les données à notre disposition. Dans cette section, nous allons explorer différentes pistes qui pourraient potentiellement avoir un impact positif sur nos prédictions, que ce soit de répérer des données éloignées du reste de l'ensemble, de répérer des tendances, de détecter des instances de multicolinéarité, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape pour traiter les données est de copier les données d'entraînement dans une variable \"data\" afin d'éviter de corrompre les données originales lors de nos manipulations. On peut ensuite retirer les valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire une copie initiale du dataframe\n",
    "data = deepcopy(train)\n",
    "\n",
    "# retirer les colonnes ayant des données vides de notre dataframe\n",
    "data = dropmissing(data)\n",
    "\n",
    "# procéder au prétraitement par défaut\n",
    "default_prerocessing(data)\n",
    "\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer s'il y a des différences significatives entre le jeu de données d'entraînement et le jeu de données de test\n",
    "\n",
    "data_stats = describe(data)\n",
    "testing_stats = describe(test)\n",
    "\n",
    "print(\"Training Set: \\n\", data_stats)\n",
    "print(\"\\n Testing Set: \\n\", testing_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons commencer par analyser chacune des variables explicatives potentielles en détail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Année"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première variable explicative est l'année de fabrication du véhicule. Nous avons commencé par regarder la tendance de la consommation d'essence au fil des ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:annee,\n",
    "    y=:consommation,\n",
    "    Geom.boxplot,\n",
    "    Guide.title(\"Consommation d'essence en fonction de l'année du véhicule\"),\n",
    "    Guide.xlabel(\"Année\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    "    Guide.xticks(ticks=collect(2013:1:2025)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tirer quelques observations de ce diagramme. D'abord, les données de l'ensemble d'entraînement sont réparties sur une période de seulement 10 ans, soit de 2014 à 2024. Ceci fait en sorte que les consommations d'essence correspondantes varieront peu d'une année à l'autre, car les véhicules ne se sont pas améliorés technologiquement de façon assez significative sur une aussi courte période pour que l'année de fabrication ait une incidence notable sur la consommation d'essence. De plus, lorsqu'on observe le diagramme, il est difficile de remarquer une tendance claire dans la variation de la consommation d'essence sur la période de 10 ans. La consommation d'essence semblait être à la hausse en 2022 et 2023, avant de rechuter en 2024. Ces variations nous semblent difficiles à modéliser. Pour toutes ces raisons, il nous semble initialement que l'année de fabrication soit une variable explicative de faible impact sur les prédictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous nous sommes questionnés par rapport à la grosseur des chiffres reliées à l'année dans un modèle. En effet, les autres données numériques étant le nombre de cylindres et la cylindrée, qui ont tous les deux des valeurs nettement inférieures à un chiffre comme 2020, nous nous demandions si cette disparité pouvait avoir un impact sur la qualité de nos prédictions. Nous avons donc opté pour la stratégie de changer la variable explicative de l'année de fabrication pour une variable d'âge, qui serait entre 1 et 10 ans, et qui serait beaucoup plus proche des valeurs des autres variables explicatives. Ci-dessous se trouve notre façon de procéder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age = 2024 .- data.annee\n",
    "\n",
    "select!(data, Not(:annee))\n",
    "first(data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de ces données, nous avons essayé de remplacer l'année de fabrication par l'âge du véhicule dans notre modèle le plus performant. Nous avons noté une amélioration de ${10}^{-12}$ de notre RMSE. Il va donc sans dire que cette modification de nos variables explicatives était totalement inutile. Nous garderons donc l'année de fabrication pour la suite de nos tests, bien que nous ayons peu d'espoir que cette variable se retrouve dans le modèle final étant donné sa faible corrélation avec la consommation d'essence pour toutes les raisons mentionnées ci-haut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type de véhicule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons maintenant une seconde variable, soit le type de véhicule. Commençons par vérifier le nombre de types différents dans l'échantillo, ainsi que la quantité d'observations pour chacune des catégories listées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_categories = unique(skipmissing(data[:, :type]))\n",
    "occurences = [sum(skipmissing(data[:, :type]) .== category) for category in unique_categories]\n",
    "occurences = DataFrame(category = unique_categories, occurences = occurences)\n",
    "sort!(occurences, :occurences, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le constater, il y a des grandes différences au niveau du nombre d'observations pour chaque type de véhicule: certains, comme les VUS petits, sont représentés à de nombreuses reprises (86), tandis que d'autres, comme les camionnettes standards, sont très rares (2). On peut également illustrer ces données sous la forme d'un graphique des occurences selon les différents types de véhicules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    occurences,\n",
    "    x=:category,\n",
    "    y=:occurences,\n",
    "    Geom.bar,\n",
    "    Guide.title(\"Répartition des types de véhicules\"),\n",
    "    Guide.xlabel(\"Type de véhicule\"),\n",
    "    Guide.ylabel(\"Occurrences\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculons maintenant les moyennes de consommation par type de véhicule, ce qui pourrait nous informer sur la variable d'intérêt : en effet, il nous semble a priori logique qu'un type de véhicule plus gros comme une camionnette consomme beaucoup plus qu'un véhicule léger comme une voiture mini-compacte. On affiche aussi ces valeurs dans un graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_values = combine(groupby(data, :type), :consommation => mean => :mean_consommation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@df mean_values bar(:type, :mean_consommation, xlabel=\"Type de véhicule\", ylabel=\"Consommation Moyenne\", title=\"Consommation moyenne par type de véhicule\", legend=false, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir du graphique ci-haut représentant la consommation d'essence moyenne en fonction du type de véhicule, il est possbile de remarquer des similarités par rapport à la consommation de certains types de véhicules. Afin de contrer le fait que certaines catégories ont très peu d'observations, ce qui rend l'interprétation des tendances générales plus difficile en raison du bruit, nous avons décidé de regrouper certaines catégories similaires. Cela permet aussi de contribuer à réduire la multicolinéarité en réduisant le nombre de variables explicatives similaires. La méthode que nous avons employée est la suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"monospace\", \"camionnette_petit\",]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc regroupé les caétgories \"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\" et \"voiture_moyenne\" dans la nouvelle catégorie \"petits_véhicules\", les \"voiture_sous_compacte\", \"monospace\" et \"camionnette_petit\" dans la nouvelle catégorie \"véhicules_moyens\", et tous les autres dans la catégorie \"grands_véhicules\". Analysons maintenant les performances de ces trois nouvelles catégories dans un modèle de régression linéaire, en les comparant avec les performances des types de véhicules avant le regroupement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithCategorie = deepcopy(data)\n",
    "\n",
    "dataWithCategorie[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in dataWithCategorie[:, :type]]\n",
    "categorical_cols = [:categorie_vehicule,]\n",
    "\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(dataWithCategorie[!, col])\n",
    "end\n",
    "\n",
    "data_type_encoded = one_hot_encode(dataWithCategorie, categorical_cols, levels_dict)\n",
    "model = lm(@formula(consommation ~ categorie_vehicule_petits_véhicules + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens), dataWithCategorie)\n",
    "\n",
    "dataWithCategorie.predicted = predict(model)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((dataWithCategorie.consommation .- dataWithCategorie.predicted).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithType = deepcopy(data)\n",
    "\n",
    "categorical_cols = [:type,]\n",
    "\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(dataWithType[!, col])\n",
    "end\n",
    "\n",
    "data_type_encoded = one_hot_encode(dataWithType, categorical_cols, levels_dict)\n",
    "\n",
    "model = lm(@formula(consommation ~ type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte + type_VUS_standard + type_monospace + \n",
    "                    type_camionnette_petit + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard), dataWithType)\n",
    "\n",
    "dataWithType.predicted = predict(model)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((dataWithType.consommation .- dataWithType.predicted).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À la lumière des valeurs obtenues, on conclut que lorque seules ces nouvelles catégories sont incluses dans le modèle, elles performent moins bien que lorsque seuls les types originals sont inclus dans le modèle, autant au niveau du ${R^2}$ que du RMSE. Cette tentative de réduire la dimensionalité du vecteur de paramètres est donc un échec dans le cas où le type est le seul paramètre étudié.  Nous verrons plus loin que lorsque le regroupement par catégories est associé à d'autres variables explicatives, cette méthode bonifie le RMSE.\n",
    "\n",
    "Regardons maintenant la relation entre le type de véhicule et la cylindrée afin de vérifier si certains types de véhicules ont une consommation plus élevée en raison d'une cylindrée importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=:consommation,\n",
    "    color=:type,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée, catégorisée par type de véhicule\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    "    Guide.colorkey(\"Type de véhicule\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cylindrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Généralement, la cylindée d'un véhicule est hautement corrélée à la consommation d'essence de celui-ci. Toutefois, la cylindrée est une variable continue avec énormément de valeurs uniques, ce qui peut compliqué la modélisation de la consommation d'essence. De plus, la distibuion des échantillions est asymétrique. Nous avons donc décidé d'étudier la nécessité de transformer cette variable en une variable catégorielle. Pour ce faire, nous avons d'abord regardé la distribution des cylindrées dans notre ensemble de données. \n",
    "\n",
    "L'idée est de créer des catégories de cylindrées, par exemple, les véhicules avec une cylindrée de moins de 2L, entre 2L et 3L, et plus de 3L. Nous avons donc créé un histogramme de la distribution des cylindrées pour nous aider à déterminer les catégories à utiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cylindree = unique(skipmissing(data[:, :cylindree]))\n",
    "occurences_cylindree = [sum(skipmissing(data[:, :cylindree]) .== cylindree) for cylindree in unique_cylindree]\n",
    "occurences_cylindree = DataFrame(cylindree = unique_cylindree, occurences = occurences_cylindree)\n",
    "\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "Gadfly.plot(\n",
    "    occurences_cylindree,\n",
    "    x=:cylindree,\n",
    "    y=:occurences,\n",
    "    Geom.bar,\n",
    "    Guide.title(\"Répartition des cylindrées\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Occurrences\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme mentionné, la distribution des cylindrées est très asymétrique, avec une majorité de véhicules ayant une cylindrée de moins de 3L.  Dans notre modèle final, nous n'avons toutefois pas pris compte de la correction de cette asymmétrie.  Nous allons donc plutôt étudier la relation entre la cylindrée et la consommation d'essence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster un modèle de régression linéaire\n",
    "model = lm(@formula(consommation ~ cylindree), data)\n",
    "\n",
    "# Prédire les valeurs de consommation pour tracer la ligne\n",
    "data.predicted = predict(model)\n",
    "\n",
    "# Tracer avec Gadfly\n",
    "p = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    layer(data, x=:cylindree, y=:predicted, Geom.line, Theme(default_color=\"red\")),\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")\n",
    "\n",
    "display(p)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((data.consommation .- data.predicted).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse)\n",
    "\n",
    "# calcul des résidus\n",
    "res = data.consommation .- data.predicted\n",
    "\n",
    "p1 = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=res,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Résidus de la régression linéaire\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Résidus\"),\n",
    ")\n",
    "display(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, il semble y avoir une relation croissante entre la cylindrée et la consommation de carburant. C'est ce qui était attendu, mais nous remarquons que la relation n'est pas parfaitemnt linéaire. Si nous voulons respecter le principe de linéarité, nous devons transformer la variable explicative pour respecter l'hypothèses 1. Pour ce faire, nous allons appliquer le logarithme des cylindrées pour voir si cela améliore la linéarité de la relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cylindree = log.(data.cylindree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster un modèle de régression linéaire\n",
    "model = lm(@formula(consommation ~ cylindree), data)\n",
    "\n",
    "# Prédire les valeurs de consommation pour tracer la ligne\n",
    "data.predicted = predict(model)\n",
    "\n",
    "# Tracer avec Gadfly\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    layer(data, x=:cylindree, y=:predicted, Geom.line, Theme(default_color=\"red\")),\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    "    Guide.colorkey(\"Catégorie de cylindrée\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer le logaritme sur la cylindree\n",
    "data.cylindree = log.(data.cylindree)\n",
    "\n",
    "println(\"R²: \", r2(model))\n",
    "rmse = sqrt(mean((data.consommation .- data.predicted).^2))\n",
    "println(\"RMSE: \", rmse)\n",
    "\n",
    "# calcul des résidus\n",
    "res = data.consommation .- data.predicted\n",
    "\n",
    "p1 = Gadfly.plot(\n",
    "    data,\n",
    "    x=:cylindree,\n",
    "    y=res,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Résidus de la régression linéaire\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Résidus\"),\n",
    ")\n",
    "display(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, la relation entre la consommation d'essence et la cylindrée semble être plus linéaire après avoir appliqué le logarithme. Nous allons donc utiliser cette transformation pour la suite de notre analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nombre de cylindres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons maintenant une autre variable numérique : le nombre de cylindres du moteur. Commençons par déterminer combien de variables uniques existent pour cette variable explicative potentielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nb_cylindres = unique(data[:, :nombre_cylindres])\n",
    "occurences = [sum(data[:, :nombre_cylindres] .== nb_cylindres) for nb_cylindres in unique_nb_cylindres]\n",
    "occurences = DataFrame(nb_cylindres = unique_nb_cylindres, occurences = occurences)\n",
    "sort!(occurences, :occurences, rev=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le constater, la grande majorité des véhicules étudiés ont 4 cylindres (148), 6 cylindres (87), 8 cylindres (51) ou 3 cylindres (24). Seuls quelques véhicules ont un plus grand nombre de cylindres (3 véhicules de 12 cylindres et 3 véhicules de 10 cylindres), et une seul véhicule a 5 cylindres. Pour ces valeurs pour lesquelles nous disposons de moins de données d'entraînement, il est donc possible de penser que le modèle sera moins efficace dans ses prédictions. Ce sera une hypothèse que nous considérerons plus loin dans l'entraînement de nos modèles. On pourrait décider d'omettre ces données en appliquant la modification suivante au dataframe (conserver la valeur seulement si elle est associée à plus de 5 occurences):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = occurences[occurences.occurences .> 5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi visualiser ces données sous forme de diagramme pour obtenir une meilleure compréhension de celles-ci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Consommation d'essence en fonction du nombre de cylindres du véhicule\"),\n",
    "    Guide.xlabel(\"Nombre de cylindres (log)\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reconnait ici une forme logarithmique. Essayons d'appliquer un log aux valeurs du nombre de cylindre pour obtenir une distribution linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nombre_cylindres = log.(data.nombre_cylindres)\n",
    "\n",
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Consommation d'essence en fonction du nombre de cylindres du véhicule (log)\"),\n",
    "    Guide.xlabel(\"Nombre de cylindres (log)\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on utilise la valeur ajustée avec le logarithme du nombre de cylindres, on obtient les prédictions préliminaires suivantes avec les résidus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(consommation ~ nombre_cylindres), data)\n",
    "\n",
    "data.predicted = predict(model)\n",
    "\n",
    "p = Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=:consommation,\n",
    "    Geom.point,\n",
    "    layer(data, x=:nombre_cylindres, y=:predicted, Geom.line, Theme(default_color=\"red\")),\n",
    "    Guide.title(\"Consommation d'essence en fonction de la cylindrée\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation (L/100km)\"),\n",
    ")\n",
    "\n",
    "display(p)\n",
    "\n",
    "\n",
    "p1 = Gadfly.plot(\n",
    "    data,\n",
    "    x=:nombre_cylindres,\n",
    "    y=res,\n",
    "    Geom.point,\n",
    "    Guide.title(\"Résidus de la régression linéaire\"),\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Résidus\"),\n",
    ")\n",
    "\n",
    "display(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit donc que plus le nombre de cylindres est grand, plus la consommation d'essence moyenne a tendance à augmenter aussi. Compte tenu de cette observation et du fort coefficient de corrélation entre la consommation et le nombre de cylindres, il semble que ce dernier constitue une variable explicative de fort intérêt pour notre modèle prédictif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transmission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ce qui concerne le type de transmission, nous avons commencé par observer la distribution des catégories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [data]\n",
    "    println(\"Nombre d'observations par type de transmission :\")\n",
    "    println(combine(groupby(df, :transmission), nrow))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir, les types de transmission sont représentées inégalement dans l'ensemble de données. Les transmissions integrale et à traction sont largement représentées, tandis que les transmissions à propulsion et 4x4 sont sous-représentées. Cela nous mène à questionner l'effet de ce manque sur les prédictions. Effectivement, si les types de transmission sont corrélés à la consommation d'essence, le fait que certaines catégories soient sous-représentées pourrait biaiser nos prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramme de la consommation moyenne en fonction du type de transmission\n",
    "set_default_plot_size(20cm, 20cm)\n",
    "\n",
    "mean_consommation = combine(groupby(data, :transmission), :consommation => mean => :mean_consommation)\n",
    "# moyenne par type de transmission\n",
    "println(mean_consommation)\n",
    "\n",
    "Gadfly.plot(\n",
    "    mean_consommation,\n",
    "    x=:transmission,\n",
    "    y=:mean_consommation,\n",
    "    Geom.bar,\n",
    "    Guide.xlabel(\"Transmission\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction du type de transmission\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme, les prédictions risquent d'être biaisées vers des valeurs associées aux classes majoritaires (\"integrale\" ou \"traction\"), nous pourrions poser l'hypothèse que le modèle risque de sous-estimer non seulement la consommation des véhicules avec une transmission 4x4 et propulsion, mais aussi les prédictions globales en raison de la forte représentation de la transmission traction. (Voir histogramme de la consommation par type de transmission). Pour pallier à ce problème, nous pourrions envisager de pondérer ou de regrouper les classes de transmission pour équilibrer les données. Par exemple, nous pourrions ajouter un poids élevé à la classe \"4x4\" et un poids plus faible à la classe \"Traction\" pour compenser leur représentation respective. Nous pourrions également regrouper les classes \"Intégrale\" et \"Propulsion\" en une seule catégorie pour augmenter leur représentation dans l'ensemble de données, si leur distinction n'apporte pas de valeur ajoutée au modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approche A: Ajustement de poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") # ne contient pas la variable consommation\n",
    "\n",
    "Random.seed!(1234) # pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) # 80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) # échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) # échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeux de données avec 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Jeux de données sans 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Remplacer les virgules par des points dans 'cylindree' pour pouvoir convertir en float ensuite\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Remplacer les virgules par des points dans 'consommation' pour pouvoir convertir en float ensuite\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convertir 'cylindree' en float dans tous les datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convertir 'consommation' en float dans les datasets avec 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Retirer les valeurs manquantes dans tous les datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(train, :transmission), nrow => :nrow)\n",
    "\n",
    "# Étape 2: calculer le nombre total d'échantillons et le nombre de classes\n",
    "total_samples = sum(counts.nrow)\n",
    "num_classes = nrow(counts)\n",
    "\n",
    "# Étape 3: Calculer les poids pour chaque classe\n",
    "counts.Weight = total_samples ./ (num_classes .* counts.nrow)\n",
    "\n",
    "# Étape 4: Joindre les poids à l'ensemble de données d'entraînement\n",
    "train = leftjoin(train, counts[:, [:transmission, :Weight]], on=:transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les colonnes catégorielles\n",
    "categorical_cols = [:transmission,:type]\n",
    "\n",
    "# Créer un dictionnaire pour stocker les niveaux de chaque colonne catégorielle\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(train)\n",
    "dropmissing!(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster le modèle avec les poids\n",
    "@time modelA = fit(LinearModel, @formula(consommation ~ transmission_propulsion + transmission_traction + transmission_integrale + transmission_4x4), train, wts = train.Weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction avec l'ensemble de validation\n",
    "valid_prediction = GLM.predict(modelA, valid)\n",
    "train_prediction = GLM.predict(modelA, train)\n",
    "\n",
    "# Trouver la moyenne de prédiction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "mean_prediction_train = mean(train_prediction)\n",
    "\n",
    "# Remplacer les missing par la moyenne\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "train_prediction = coalesce.(train_prediction, mean_prediction_train)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse_valid = sqrt(mean((valid_prediction - valid.consommation).^2))\n",
    "rmse_train = sqrt(mean((train_prediction - train.consommation).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse_valid)\n",
    "println(\"RMSE train: \", rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'approche A, le rmse nous donne 1.081 ce qui signifie que les prédicitons ne sont pas affectées positivement à l'ajout de poids selon la transmissions. Nous avons donc décidé de ne pas utiliser cette approche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approche B: Combinaison de catégories similaires \n",
    "\n",
    "Nous devons tester la significativité statistique de la différence entre les catégories de transmission. Pour ce faire, nous avons effectué un test de student pour comparer les moyennes de consommation d'essence entre les différentes catégories de transmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") # ne contient pas la variable consommation\n",
    "\n",
    "Random.seed!(1234) # pour la reproductibilité\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) # 80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) # échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) # échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = deepcopy(train)\n",
    "valid_data = deepcopy(valid)\n",
    "\n",
    "# Jeux de données avec 'consommation'\n",
    "datasets_with_consommation = [train_data, valid_data]\n",
    "\n",
    "# Jeux de données sans 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Appliquer les remplacements à 'cylindree' uniquement dans les jeux de données qui le contiennent\n",
    "for df in [train_data, valid_data, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Appliquer les remplacements à 'consommation' uniquement dans les jeux de données qui le contiennent\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convertir 'cylindree' en float dans tous les jeux de données\n",
    "for df in [train_data, valid_data, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convertir 'consommation' en float dans les jeux de données ayant la colonne 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Retirer les valeurs manquantes dans tous les jeux de données\n",
    "for df in [train_data, valid_data, test]\n",
    "    dropmissing!(df)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour calculer la moyenne\n",
    "\n",
    "function t_test_equal_variances(group1, group2)\n",
    "    # Tailles des échantillons\n",
    "    n1 = length(group1)\n",
    "    n2 = length(group2)\n",
    "\n",
    "    # Moyennes des deux groupes\n",
    "    μ1 = mean(group1)\n",
    "    μ2 = mean(group2)\n",
    "\n",
    "    # Variances des deux groupes\n",
    "    s1² = var(group1)\n",
    "    s2² = var(group2)\n",
    "\n",
    "    # Variance combinée pondérée\n",
    "    sp² = ((n1 - 1) * s1² + (n2 - 1) * s2²) / (n1 + n2 - 2)\n",
    "\n",
    "    # Statistique t\n",
    "    t_stat = (μ1 - μ2) / sqrt(sp² * (1 / n1 + 1 / n2))\n",
    "\n",
    "    # Degrés de liberté\n",
    "    df = n1 + n2 - 2\n",
    "    \n",
    "    return t_stat, df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemple d'utilisation\n",
    "group_integrale = train_data[train_data.transmission .== \"integrale\", :consommation]\n",
    "group_4x4 = train_data[train_data.transmission .== \"4x4\", :consommation]\n",
    "\n",
    "# Calcul du test t\n",
    "t_stat, df = t_test_equal_variances(group_integrale, group_4x4)\n",
    "\n",
    "absolut_t_stat = abs(t_stat)\n",
    "\n",
    "pvalue = 2 * (1 - cdf(TDist(df), absolut_t_stat))\n",
    "\n",
    "println(\"Statistique t : $absolut_t_stat\")\n",
    "println(\"p-valeur : $pvalue\")\n",
    "println(\"Degrés de liberté : $df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme le test de student nous donne une p-value > 0.05, nous ne pouvons pas rejeter l'hypothèse nulle selon laquelle les moyennes de consommation d'essence entre les différentes catégories de transmission sont égales. Cela signifie que les différences de consommation d'essence entre les catégories de transmission ne sont pas statistiquement significatives. Par conséquent, nous pouvons regrouper les catégories de transmission similaires pour augmenter leur représentation dans l'ensemble de données sans affecter la qualité des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une nouvelle colonne pour les catégories de transmission\n",
    "# si la transmission est 4x4, la remplacer par \"integrale\"\n",
    "train_data.transmission = ifelse.(train_data.transmission .== \"4x4\", \"integrale\", train_data.transmission)\n",
    "valid_data.transmission = ifelse.(valid_data.transmission .== \"4x4\", \"integrale\", valid_data.transmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder la variable boite\n",
    "for df in [train_data, valid_data, test]\n",
    "    df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "end\n",
    "\n",
    "# définir les colonnes catégorielles\n",
    "categorical_cols = [:type, :transmission]\n",
    "\n",
    "# créer un dictionnaire pour stocker les niveaux de chaque colonne catégorielle\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train_data[!, col])\n",
    "end\n",
    "\n",
    "train_data = one_hot_encode(train_data, categorical_cols, levels_dict)\n",
    "valid_data = one_hot_encode(valid_data, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)\n",
    "\n",
    "println(names(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time modelB = lm(@formula(consommation ~ \n",
    "    transmission_integrale + transmission_traction + transmission_propulsion), train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction avec l'ensemble de validation\n",
    "valid_prediction = GLM.predict(modelB, valid_data)\n",
    "\n",
    "# Trouver la moyenne de prédiction\n",
    "mean_prediction = mean(valid_prediction)\n",
    "\n",
    "# Remplacer les missing par la moyenne\n",
    "valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse_valid = sqrt(mean((valid_prediction - valid_data.consommation).^2))\n",
    "\n",
    "println(\"RMSE: \", rmse_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Boîte\n",
    "\n",
    "Terminons notre analyse en regardant la dernière variable explicative potentielle avec laquelle nous pouvons travailler, soit la boîte du moteur.  Cette variable peut prendre deux valeurs seulement : automatique ou manuelle.  Commençons par comptabiliser le nombre d'occurences de chaque type au sein de notre ensemble d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = combine(groupby(data, :boite), nrow => :count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate donc qu'il y a beaucoup plus d'observations dans la catégorie des véhicules automatiques (268) que pour les véhicules manuels (49). Regardons maintenant la consommation d'essence associée à chacun des types de boîte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default_plot_size(16cm, 12cm)\n",
    "Gadfly.plot(\n",
    "    data,\n",
    "    x=:boite,\n",
    "    y=:consommation,\n",
    "    Geom.boxplot,\n",
    "    Guide.xlabel(\"Boîte\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction du type de boîte\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate ici que les deux boîtes se comportent de manière similaire au niveau de la consommation moyenne, avec un écart interquartile un peu plus important pour les véhicules automatiques que pour les véhicules manuels. La variance de la distribution de véhicules automatiques est donc plus grande. On constate aussi la présence d'une donnée abherrante dans la distribution de données du côté manuel, qui pourrait gagner à être retirée lors de l'entraînement du modèle.  Puisque la boîte en soi ne nous informe que très peu sur la consommation d'essence d'un véhciule, on s'intéresse maintenant à la relation entre cette variable et d'autres éléments du jeu de données, notamment le type de véhicule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(data,\n",
    "    x = :type,\n",
    "    y = :consommation,\n",
    "    color = :boite,\n",
    "    Geom.point,\n",
    "    Scale.x_discrete(labels=identity),\n",
    "    Theme(bar_spacing=0.7)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qu'on constate en observant ce graphique, c'est que pour certains types de véhicules, il est impossible que la boîte soit manuelle dans notre jeu de données d'entraînement. Cela fait en sorte qu'il existe possiblement une lacune dans la collecte de données qui ne sont pas assez représentatives, ou alors qu'il s'agit d'un phénomène qu'on pourrait constater en industrie.  Dans tous les cas, cette disparité entre les types de véhicule au niveau de la boîte peut emmener le modèle à faire des prédictions moins fiables pour le types de véhicules n'ayant pas des données à la fois maunelles et automatiques comme les VUS ou les camionnettes. De plus, on ne semble pas détecter que pour un ou des types de véhicules en particulier, le type de boîte ait un gros impact sur la consommation d'essence, pusique les points jaunes se retrouvent souvent au milieu des points bleus.\n",
    "\n",
    "Une dernière observation que nous pouvons faire est de tracer le graphique de la consommation d'essence en fonction de la cylindrée, une variable explicative que nous avons déjà prouvé comme étant pertinente, mais cette fois-ci selon le type de boîte (une ligne pour les boîtes automatiques et une autre pour les boîtes manuelles). Encore une fois, on constate qu'il y a peu d'incidence sur la consommation d'essence entre les deux modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data = combine(groupby(data, [:cylindree, :boite]), \n",
    "    :consommation => mean => :avg_consumption)\n",
    "\n",
    "Gadfly.plot(aggregated_data,\n",
    "    x = :cylindree,\n",
    "    y = :avg_consumption,\n",
    "    color = :boite,\n",
    "    Geom.line,\n",
    "    Guide.xlabel(\"Cylindrée\"),\n",
    "    Guide.ylabel(\"Consommation moyenne (L/100km)\"),\n",
    "    Guide.title(\"Consommation moyenne en fonction de la cylindrée et du type de boîte\"),\n",
    "    Theme(default_color=\"blue\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrélation entre les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [:age, :nombre_cylindres, :cylindree, :consommation]\n",
    "\n",
    "M = cor(Matrix(data[:, numeric_cols]))\n",
    "\n",
    "# Afficher la matrice de corrélation\n",
    "println(\"Matrice de corrélation :\")\n",
    "println(M)\n",
    "\n",
    "# PLOT\n",
    "(n,m) = size(M)\n",
    "heatmap(M, fc=cgrad([:white,:dodgerblue4]), xticks=(1:m,numeric_cols), xrot=90, yticks=(1:m,numeric_cols), yflip=true)\n",
    "annotate!([(j, i, text(round(M[i,j],digits=3), 8,\"Computer Modern\",:black)) for i in 1:n for j in 1:m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `nombre_cylindres` et `cylindree` est très élevée, ce qui indique une forte relation positive. Cela suggère que le nombre de cylindres est fortement associé à la cylindrée des véhicules.\n",
    "\n",
    "2. La corrélation entre `cylindree` et `consommation` est également élevée, montrant qu'une augmentation de la cylindrée est associée à une augmentation de la consommation (par exemple, les moteurs plus gros consomment plus de carburant).\n",
    "\n",
    "3. Une corrélation similaire existe entre `nombre_cylindres` et `consommation`, ce qui est logique, car le nombre de cylindres et la cylindrée sont liés.\n",
    "\n",
    "4. Les corrélations entre annee et les autres variables sont faibles et négatives, indiquant que les variables comme le nombre de cylindres, la cylindrée et la consommation ont légèrement diminué avec le temps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous en avons appris davantage sur les différentes relations entre les variables, il est temps de quantifier la force qu'elles auront sur la variable d'intérêt par une régression linéaire. Pour commencer, nous partitionnons nos données en un ensemble d'entrainement et un ensemble de validation. Pour ce faire, nous utilisons la stratégie du ratio 80/20 et nous intégrerons une validation croisée èa k blocs pour évaluer la performance de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\")\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilité\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement \n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #Échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #Échantillon de validation. On prend les données qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "first(train, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au début du concours, nous ne connaissions pas trop les différentes capacités de la librairie CSV et nous ne savions pas que de simplement ajouter un decimal=',' permettait d'accomplir ce que nous accomplissons dans la prochaine cellule. Nous avons donc décidé de simplement remplacer les virgules par des points dans les colonnes numériques qui sont en String par défaut dans les jeux de données, puis appliquer la conversion en Float directement et retirer les valeurs manquantes à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacite_moteur = :nombre_cylindres * :cylindree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert annee column into age\n",
    "train.age = 2024 .- train.annee\n",
    "valid.age = 2024 .- valid.annee\n",
    "test.age = 2024 .- test.annee\n",
    "\n",
    "train = select!(train, Not(:annee))\n",
    "valid = select!(valid, Not(:annee))\n",
    "test = select!(test, Not(:annee))\n",
    "\n",
    "## drop missing values\n",
    "train = dropmissing(train)\n",
    "valid = dropmissing(valid)\n",
    "test = dropmissing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prétraitement\n",
    "\n",
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est plutôt ici que le pre-processing est appliqué aux jeux de données pertinents. Effectivement, cette cellule combine les différentes conclusions tirées dans la section d'exploration de données pour exploiter les différentes variables explicatives de manière optimale. Par exemple  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = remove_outliers_by_iqr(train, :cylindree, :consommation)\n",
    "valid = remove_outliers_by_iqr(valid, :cylindree, :consommation)\n",
    "\n",
    "train.cylindree = log.(train.cylindree)\n",
    "valid.cylindree = log.(valid.cylindree)\n",
    "test.cylindree = log.(test.cylindree)\n",
    "\n",
    "train.nombre_cylindres = log.(train.nombre_cylindres)\n",
    "valid.nombre_cylindres = log.(valid.nombre_cylindres)\n",
    "test.nombre_cylindres = log.(test.nombre_cylindres)\n",
    "\n",
    "train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)\n",
    "valid.transmission = ifelse.(valid.transmission .== \"4x4\", \"integrale\", valid.transmission)\n",
    "test.transmission = ifelse.(test.transmission .== \"4x4\", \"integrale\", test.transmission)\n",
    "\n",
    "train.transmission = ifelse.(train.transmission .== \"propulsion\", \"integrale\", train.transmission)\n",
    "valid.transmission = ifelse.(valid.transmission .== \"propulsion\", \"integrale\", valid.transmission)\n",
    "test.transmission = ifelse.(test.transmission .== \"propulsion\", \"integrale\", test.transmission)\n",
    "\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:categorie_vehicule, :transmission, :type]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #standardize the data\n",
    "# function standardize(df)\n",
    "#     for col in names(df)\n",
    "#         if eltype(df[!, col]) <: Number\n",
    "#             df[!, col] = (df[!, col] .- mean(df[!, col])) ./ std(df[!, col])\n",
    "#         end\n",
    "#     end\n",
    "#     return df\n",
    "# end\n",
    "\n",
    "# numeric_cols = [:age, :cylindree]\n",
    "\n",
    "# train[!, numeric_cols] = standardize(train[!, numeric_cols])\n",
    "# valid[!, numeric_cols] = standardize(valid[!, numeric_cols])\n",
    "# test[!, numeric_cols] = standardize(test[!, numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, valid, test]\n",
    "    df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = :consommation\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X_train = Matrix(train[:, Not([target])])\n",
    "y_train = train[!, target]\n",
    "X_valid = Matrix(valid[:, Not([target])])\n",
    "y_valid = valid[!, target]\n",
    "X_test = Matrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm(@formula(consommation ~ transmission_traction + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens + cylindree), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cross validation\n",
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.consommation\n",
    "X = select(data_k_folds, Not(:consommation))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 10 # meilleur que 5\n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    valid_indices = (i * fold_size + 1):((i + 1) * fold_size)\n",
    "    train_indices = setdiff(1:n, valid_indices)\n",
    "    \n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_valid = X[valid_indices, :]\n",
    "    y_valid = y[valid_indices]\n",
    "\n",
    "    model = lm(@formula(consommation ~ transmission_integrale + transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens + cylindree), data_k_folds) #Meilleur\n",
    "    \n",
    "    ŷ_valid = GLM.predict(model, X_valid)\n",
    "    rms = sqrt(mean((ŷ_valid .- y_valid).^2))\n",
    "    push!(rms_scores, rms)\n",
    "end\n",
    "\n",
    "moyenne_rmse = mean(rms_scores)\n",
    "println(\"Moyenne RMSE k-fold : $moyenne_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_train = GLM.predict(model, train)\n",
    "ŷ_valid = GLM.predict(model, valid)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_train = sqrt(mean((ŷ_train .- train.consommation).^2))\n",
    "rmse_valid = sqrt(mean((ŷ_valid .- valid.consommation).^2))\n",
    "\n",
    "valid.predicted = ŷ_valid\n",
    "\n",
    "#plot dirstribtuion of residuals\n",
    "residuals = ŷ_valid .- valid.consommation\n",
    "\n",
    "println(\"RMSE on the training set: $rmse_train\")\n",
    "println(\"RMSE on the validation set: $rmse_valid\")\n",
    "#plot the residuals vs the predicted values\n",
    "s = scatter(ŷ_valid, residuals, title=\"Residuals vs Predicted values\", xlabel=\"Predicted values\", ylabel=\"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature matrix and target vector\n",
    "X_train = Matrix(train[:, Not([:consommation])])\n",
    "y_train = Vector(train.consommation)\n",
    "X_valid = Matrix(valid[:, Not([:consommation])])\n",
    "y_valid = Vector(valid.consommation)\n",
    "X_test = Matrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_formulas = [\n",
    "    @formula(consommation ~ nombre_cylindres),\n",
    "    @formula(consommation ~ cylindree),\n",
    "    @formula(consommation ~ cylindree + nombre_cylindres),\n",
    "    @formula(consommation ~ cylindree + boite),\n",
    "    @formula(consommation ~ cylindree + transmission_integrale),\n",
    "    @formula(consommation ~ transmission_integrale + transmission_traction),\n",
    "    @formula(consommation ~ transmission_integrale + nombre_cylindres),\n",
    "    @formula(consommation ~ transmission_integrale + transmission_traction + cylindree),\n",
    "    @formula(consommation ~ transmission_integrale + cylindree),\n",
    "    @formula(consommation ~ transmission_integrale + cylindree),\n",
    "    @formula(consommation ~ transmission_integrale + cylindree + nombre_cylindres),\n",
    "    @formula(consommation ~ transmission_traction + cylindree + nombre_cylindres),\n",
    "    @formula(consommation ~ transmission_integrale + cylindree + nombre_cylindres + boite),\n",
    "    @formula(consommation ~ transmission_traction + cylindree + nombre_cylindres + boite),\n",
    "    @formula(consommation ~ transmission_integrale + transmission_traction + cylindree + nombre_cylindres + boite),\n",
    "    @formula(consommation ~ transmission_traction + transmission_integrale + cylindree + nombre_cylindres + boite),\n",
    "    @formula(consommation ~ transmission_integrale + categorie_vehicule_petits_véhicules + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens + boite + cylindree),\n",
    "    @formula(consommation ~ transmission_integrale + transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens + cylindree),\n",
    "    @formula(consommation ~ transmission_integrale + transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_grands_véhicules + categorie_vehicule_véhicules_moyens + cylindree + boite),\n",
    "    @formula(consommation ~ categorie_vehicule_petits_véhicules + categorie_vehicule_véhicules_moyens + categorie_vehicule_grands_véhicules + transmission_traction + cylindree + boite),   \n",
    "    @formula(consommation ~ categorie_vehicule_petits_véhicules + categorie_vehicule_véhicules_moyens + categorie_vehicule_grands_véhicules + transmission_traction + cylindree + boite),\n",
    "    @formula(consommation ~ transmission_traction  + cylindree + boite),\n",
    "    @formula(consommation ~ transmission_integrale + cylindree + boite),\n",
    "    @formula(consommation ~ transmission_traction + cylindree + type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte + type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard + transmission_integrale + boite),\n",
    "    @formula(consommation ~ cylindree +  type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte + type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard + transmission_integrale + transmission_traction + boite),\n",
    "    @formula(consommation ~ transmission_integrale + transmission_traction + cylindree + type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte + type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard),\n",
    "    @formula(consommation ~ cylindree + type_voiture_moyenne + type_VUS_petit + type_voiture_compacte + type_voiture_deux_places + type_voiture_minicompacte + type_VUS_standard + type_voiture_sous_compacte + type_break_petit + type_voiture_grande + type_camionnette_standard)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rajs= -Inf\n",
    "best_rmse = Inf\n",
    "best_bic = -Inf\n",
    "bic_rmse = Inf\n",
    "best_model_by_raj = nothing\n",
    "best_model_by_rmse = nothing\n",
    "best_model_by_bic = nothing\n",
    "\n",
    "for formula in models_formulas\n",
    "    model = lm(formula, train)\n",
    "    ŷ = GLM.predict(model, valid)\n",
    "    local raj_valid = compute_raj(X_valid, y_valid, ŷ)\n",
    "    local bic_valid = compute_bic(X_valid, model)\n",
    "    local rmse_valid = sqrt(mean((ŷ .- y_valid).^2))\n",
    "\n",
    "    global best_rmse, best_rajs, best_model_by_rmse, best_model_by_raj, best_bic, best_model_by_bic, bic_rmse\n",
    "    if rmse_valid < best_rmse\n",
    "        best_rmse = rmse_valid\n",
    "        best_model_by_rmse = formula\n",
    "    end\n",
    "\n",
    "    if bic_valid > best_bic\n",
    "        best_bic = bic_valid\n",
    "        best_model_by_bic = formula\n",
    "        bic_rmse = rmse_valid\n",
    "    end\n",
    "\n",
    "    if raj_valid > best_rajs\n",
    "        best_rajs = raj_valid\n",
    "        best_model_by_raj = formula\n",
    "    end\n",
    "end\n",
    "\n",
    "#print best model \n",
    "println(\"\\n-------------------------------------\")\n",
    "println(\"Best model by Raj: \", best_model_by_raj)\n",
    "println(\"Best Raj: \", best_rajs)\n",
    "\n",
    "println(\"Best model by RMSE: \", best_model_by_rmse)\n",
    "println(\"Best RMSE: \", best_rmse)\n",
    "\n",
    "println(\"Best model by BIC: \", best_model_by_bic)\n",
    "println(\"Best BIC: \", best_bic)\n",
    "println(\"RMSE for the best BIC: \", bic_rmse)\n",
    "println(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ_test = GLM.predict(lm(best_model_by_rmse, train), test)\n",
    "\n",
    "n_test = size(ŷ_test, 1)\n",
    "id = 1:n_test\n",
    "df_pred = DataFrame(id=id, consommation=ŷ_test)\n",
    "\n",
    "name = string(best_rmse) * \".csv\"\n",
    "CSV.write(\"../submissions/linear/\" * name, df_pred)\n",
    "println(\"Predictions exported successfully to \" * name * \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de trouver le modèle qui offre le meilleur ajustement aux données tout en gardant une certaine simplicité. L'utilisation du BIC a été considéré afin d'en analyser les résultats. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Régression bayesienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert annee column into age\n",
    "train.age = 2024 .- train.annee\n",
    "valid.age = 2024 .- valid.annee\n",
    "test.age = 2024 .- test.annee\n",
    "\n",
    "train = select!(train, Not(:annee))\n",
    "valid = select!(valid, Not(:annee))\n",
    "test = select!(test, Not(:annee))\n",
    "\n",
    "## drop missing values\n",
    "train = dropmissing(train)\n",
    "valid = dropmissing(valid)\n",
    "test = dropmissing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Drop missing values in all datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "# # Encode 'boite' column in all datasets\n",
    "# for df in [train, valid, test]\n",
    "#     df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical columns\n",
    "categorical_cols = [:type, :transmission, :boite]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.consommation\n",
    "X_train = select(train, Not(:consommation))\n",
    "y_valid = valid.consommation\n",
    "X_valid = select(valid, Not(:consommation))\n",
    "X_test = deepcopy(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric feature indices\n",
    "feature_names = names(train)\n",
    "numeric_features = [ :cylindree, :nombre_cylindres, :age]\n",
    "numeric_indices = findall(x -> x in numeric_features, feature_names)\n",
    "\n",
    "means = mean(Matrix(X_train[:, numeric_features]), dims=1)\n",
    "stds = std(Matrix(X_train[:, numeric_features]), dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standardizer(X, means, stds)\n",
    "    X = deepcopy(X)\n",
    "    for j in 1:size(X, 2)\n",
    "        if j in numeric_indices\n",
    "            X[:, j] = (X[:, j] .- means[j]) ./ stds[j]\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = standardizer(Matrix(X_train), means, stds)\n",
    "X_valid = standardizer(Matrix(X_valid), means, stds)\n",
    "X_test = standardizer(Matrix(X_test), means, stds)\n",
    "\n",
    "y_train = Vector(y_train)\n",
    "y_valid = Vector(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression with cross-validation\n",
    "XtX = X_train' * X_train\n",
    "Xty = X_train' * y_train\n",
    "n_features = size(X_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = 10 .^ range(-5, stop=5, length=1000)\n",
    "best_rmse = Inf\n",
    "best_lambda = 0.0\n",
    "best_beta = nothing\n",
    "\n",
    "\n",
    "for λ in lambda_values\n",
    "    beta = (XtX + λ * I) \\ Xty\n",
    "    y_pred_valid = X_valid * beta\n",
    "    rmse = sqrt(mean((y_pred_valid - y_valid).^2))\n",
    "    if rmse < best_rmse\n",
    "        best_rmse = rmse\n",
    "        best_lambda = λ\n",
    "        best_beta = beta\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"Best Lambda: \", best_lambda)\n",
    "println(\"Best RMSE: \", best_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation on validation set\n",
    "y_valid_pred = X_valid * best_beta\n",
    "rmse_valid = sqrt(mean((y_valid_pred - y_valid).^2))\n",
    "println(\"Validation RMSE: \", rmse_valid)\n",
    "\n",
    "# Predictions on test set\n",
    "y_test_pred = X_test * best_beta\n",
    "\n",
    "# Prepare submission DataFrame\n",
    "n_test = size(y_test_pred, 1)\n",
    "id = 1:n_test\n",
    "df_pred = DataFrame(id=id, consommation=y_test_pred)\n",
    "\n",
    "name = \"ridge\" * string(rmse_valid) * \".csv\"\n",
    "CSV.write(\"../submissions/bayes/\" * name, df_pred)\n",
    "println(\"Predictions exported successfully to \" * name*\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation par k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.consommation\n",
    "X = select(data_k_folds, Not(:consommation))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 5  \n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    test_indices = indices[(i*fold_size + 1):min((i+1)*fold_size, n)]\n",
    "    train_indices = setdiff(indices, test_indices)\n",
    "    \n",
    "    train_data = data_k_folds[train_indices, :]\n",
    "    test_data = data_k_folds[test_indices, :]\n",
    "    \n",
    "    model = lm(@formula(consommation ~ age  + transmission_integrale + transmission_propulsion + transmission_traction + transmission_4x4 + cylindree), data_k_folds)\n",
    " \n",
    "    \n",
    "    valid_prediction = GLM.predict(model, test_data)\n",
    "    \n",
    "    mean_prediction = mean(skipmissing(valid_prediction))\n",
    "    valid_prediction = coalesce.(valid_prediction, mean_prediction)\n",
    "    \n",
    "    if any(ismissing, valid_prediction)\n",
    "        error(\"Skip les valeur missing\")\n",
    "    end\n",
    "    \n",
    "    v = max.(valid_prediction, 0) \n",
    "    \n",
    "    score = sqrt(mean((v - test_data.consommation).^2))\n",
    "    push!(rms_scores, score)\n",
    "end\n",
    "\n",
    "moyenne_rmse = mean(rms_scores)\n",
    "println(\"Moyenne RMSE : $moyenne_rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "using MultivariateStats\n",
    "using GLM\n",
    "\n",
    "# Data Cleaning and Preparation\n",
    "Random.seed!(1234) # For reproducibility\n",
    "\n",
    "# Split the data\n",
    "ntrain = round(Int, 0.8 * nrow(full_train))\n",
    "train_id = sample(1:nrow(full_train), ntrain; replace=false, ordered=true)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "train = full_train[train_id, :]\n",
    "valid = full_train[valid_id, :]\n",
    "train = full_train\n",
    "\n",
    "# Data cleaning\n",
    "for col in [:cylindree, :consommation]\n",
    "    train[!, col] = replace.(train[!, col], \",\" => \".\")\n",
    "    valid[!, col] = replace.(valid[!, col], \",\" => \".\")\n",
    "    train[!, col] = safe_parse_float.(train[!, col])\n",
    "    valid[!, col] = safe_parse_float.(valid[!, col])\n",
    "end\n",
    "\n",
    "for col in [:cylindree,]\n",
    "    test[!, col] = replace.(test[!, col], \",\" => \".\")\n",
    "    test[!, col] = safe_parse_float.(test[!, col])\n",
    "end\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:type, :transmission, :boite]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "# levels_dict = Dict()\n",
    "# for col in categorical_cols\n",
    "#     levels_dict[col] = unique(train[!, col])\n",
    "# end\n",
    "\n",
    "#train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "#valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "#test = one_hot_encode(test, categorical_cols, levels_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using Plots\n",
    "\n",
    "# Extraire les variables continues\n",
    "continuous_vars = train[:, [:cylindree, :nombre_cylindres, :consommation]]\n",
    "\n",
    "# Convertir en matrice et calculer la corrélation\n",
    "data_matrix = Matrix(continuous_vars)\n",
    "correlation_matrix = cor(data_matrix)\n",
    "\n",
    "# Afficher la matrice\n",
    "println(\"Matrice de corrélation :\")\n",
    "println(correlation_matrix)\n",
    "\n",
    "# Visualiser la matrice\n",
    "heatmap(correlation_matrix,\n",
    "    xticks = (1:size(correlation_matrix, 1), names(continuous_vars)),\n",
    "    yticks = (1:size(correlation_matrix, 2), names(continuous_vars)),\n",
    "    title = \"Matrice de corrélation\",\n",
    "    color = :coolwarm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "# Calcul des moyennes de consommation par catégorie pour 'type'\n",
    "mean_values = combine(groupby(train, :transmission), :consommation => mean => :mean_consommation)\n",
    "println(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsPlots\n",
    "\n",
    "@df mean_values bar(:transmission, :mean_consommation, xlabel=\"Type de véhicule\", ylabel=\"Consommation Moyenne\", title=\"Consommation Moyenne par transmission\", legend=false, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "# Calcul des moyennes de consommation par catégorie pour 'type'\n",
    "mean_values = combine(groupby(train, :boite), :consommation => mean => :mean_consommation)\n",
    "println(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsPlots\n",
    "\n",
    "@df mean_values bar(:boite, :mean_consommation, xlabel=\"Type de véhicule\", ylabel=\"Consommation Moyenne\", title=\"Consommation Moyenne par boite\", legend=false, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CategoricalArrays\n",
    "\n",
    "train.categorie_vehicule = CategoricalArray{String}(undef, nrow(train))\n",
    "\n",
    "for i in 1:nrow(train)\n",
    "    if train.type[i] in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        train.categorie_vehicule[i] = \"Petits Véhicules\"\n",
    "    elseif train.type[i] in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        train.categorie_vehicule[i] = \"Véhicules Moyens\"\n",
    "    else\n",
    "        train.categorie_vehicule[i] = \"Grands Véhicules\"\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"HypothesisTests\")\n",
    "\n",
    "using StatsModels, GLM, HypothesisTests\n",
    "\n",
    "# Ajuster le modèle complet\n",
    "model_full = lm(@formula(consommation ~ categorie_vehicule), train)\n",
    "\n",
    "# Ajuster le modèle réduit\n",
    "model_reduced = lm(@formula(consommation ~ 1), train)\n",
    "\n",
    "# Effectuer le test F\n",
    "ftest_result = ftest(model_full.model, model_reduced.model)\n",
    "println(ftest_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function categorize_transmission(transmission)\n",
    "    if transmission in [\"integrale\", \"4x4\", \"propulsion\"]\n",
    "        return \"AWD/RWD\"\n",
    "    else\n",
    "        return \"traction\"\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour le DataFrame 'train'\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'valid'\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'test'\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[:, :categorie_transmission] = [categorize_transmission(t) for t in train[:, :transmission]]\n",
    "valid[:, :categorie_transmission] = [categorize_transmission(t) for t in valid[:, :transmission]]\n",
    "test[:, :categorie_transmission] = [categorize_transmission(t) for t in test[:, :transmission]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, Statistics\n",
    "\n",
    "# Data cleaning\n",
    "for col in [:consommation]\n",
    "    train[!, col] = replace.(train[!, col], \",\" => \".\")\n",
    "    valid[!, col] = replace.(valid[!, col], \",\" => \".\")\n",
    "    train[!, col] = safe_parse_float.(train[!, col])\n",
    "    valid[!, col] = safe_parse_float.(valid[!, col])\n",
    "end\n",
    "\n",
    "# Calculer la consommation moyenne par combinaison de categorie_vehicule et categorie_transmission\n",
    "mean_consumption_interaction = combine(groupby(train, [:categorie_vehicule, :categorie_transmission]),\n",
    "                                      :consommation => mean => :mean_consommation)\n",
    "\n",
    "println(mean_consumption_interaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Plots, StatsBase, StatsPlots, Random, StatsModels, GLM, LinearAlgebra, MultivariateStats, Distributions\n",
    "\n",
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "function safe_parse_float(x)\n",
    "    try\n",
    "        return parse(Float64, x)\n",
    "    catch\n",
    "        return missing\n",
    "    end\n",
    "end\n",
    "\n",
    "function one_hot_encode(df, cols, levels_dict)\n",
    "    for col in cols\n",
    "        levels_col = levels_dict[col]\n",
    "        for level in levels_col\n",
    "            new_col = Symbol(string(col) * \"_\" * string(level))\n",
    "            df[!, new_col] = ifelse.(df[!, col] .== level, 1.0, 0.0)\n",
    "        end\n",
    "        select!(df, Not(col))\n",
    "    end\n",
    "    return df\n",
    "end\n",
    "\n",
    "## convert annee column into age\n",
    "train.age = 2024 .- train.annee\n",
    "valid.age = 2024 .- valid.annee\n",
    "test.age = 2024 .- test.annee\n",
    "\n",
    "train = select!(train, Not(:annee))\n",
    "valid = select!(valid, Not(:annee))\n",
    "test = select!(test, Not(:annee))\n",
    "\n",
    "## drop missing values\n",
    "train = dropmissing(train)\n",
    "valid = dropmissing(valid)\n",
    "test = dropmissing(test)\n",
    "\n",
    "# Datasets that contain 'consommation'\n",
    "datasets_with_consommation = [train, valid]\n",
    "\n",
    "# Datasets without 'consommation'\n",
    "datasets_without_consommation = [test]\n",
    "\n",
    "# Apply replacements to 'cylindree' in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = replace.(df.cylindree, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Apply replacements to 'consommation' only in datasets that have it\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = replace.(df.consommation, \",\" => \".\")\n",
    "end\n",
    "\n",
    "# Convert 'cylindree' to float in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.cylindree = safe_parse_float.(df.cylindree)\n",
    "end\n",
    "\n",
    "# Convert 'consommation' to float in datasets with 'consommation'\n",
    "for df in datasets_with_consommation\n",
    "    df.consommation = safe_parse_float.(df.consommation)\n",
    "end\n",
    "\n",
    "# Drop missing values in all datasets\n",
    "for df in [train, valid, test]\n",
    "    dropmissing!(df)\n",
    "end\n",
    "\n",
    "# Encode 'boite' column in all datasets\n",
    "for df in [train, valid, test]\n",
    "    df.boite = ifelse.(df.boite .== \"automatique\", 1.0, 0.0)\n",
    "end\n",
    "\n",
    "train.cylindree = log.(train.cylindree .+ 1)\n",
    "valid.cylindree = log.(valid.cylindree.+ 1)\n",
    "test.cylindree = log.(test.cylindree.+ 1)\n",
    "\n",
    "function remove_outliers_by_iqr(df, group_col, value_col)\n",
    "    return combine(groupby(df, group_col)) do sdf\n",
    "        q1 = quantile(sdf[!, value_col], 0.25)\n",
    "        q3 = quantile(sdf[!, value_col], 0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        filter(row -> lower_bound ≤ row[value_col] ≤ upper_bound, sdf)\n",
    "    end\n",
    "end\n",
    "#Remove outliers in the training set\n",
    "train = remove_outliers_by_iqr(train, :cylindree, :consommation)\n",
    "valid = remove_outliers_by_iqr(valid, :cylindree, :consommation)\n",
    "\n",
    "# # change type break_petit to voiture_minicompacte\n",
    "# train.type = replace(train.type, \"break_petit\" => \"voiture_minicompacte\")\n",
    "# valid.type = replace(valid.type, \"break_petit\" => \"voiture_minicompacte\")\n",
    "# test.type = replace(test.type, \"break_petit\" => \"voiture_minicompacte\")\n",
    "\n",
    "# if transmission is 4x4, change for integrale\n",
    "# train.transmission = ifelse.(train.transmission .== \"4x4\", \"integrale\", train.transmission)\n",
    "# valid.transmission = ifelse.(valid.transmission .== \"4x4\", \"integrale\", valid.transmission)\n",
    "# test.transmission = ifelse.(test.transmission .== \"4x4\", \"integrale\", test.transmission)\n",
    "function categorize_transmission(transmission)\n",
    "    if transmission in [\"integrale\", \"4x4\", \"propulsion\"]\n",
    "        return \"AWDRWD\"\n",
    "    else\n",
    "        return \"traction\"\n",
    "    end\n",
    "end\n",
    "\n",
    "function categorize_vehicle_type(vehicle_type)\n",
    "    if vehicle_type in [\"break_petit\", \"voiture_minicompacte\", \"voiture_compacte\", \"VUS_petit\", \"voiture_moyenne\"]\n",
    "        return \"petits_véhicules\"\n",
    "    elseif vehicle_type in [\"voiture_sous_compacte\", \"break_moyen\", \"monospace\", \"camionnette_petit\"]\n",
    "        return \"véhicules_moyens\"\n",
    "    else\n",
    "        return \"grands_véhicules\"\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "train[:, :categorie_transmission] = [categorize_transmission(t) for t in train[:, :transmission]]\n",
    "valid[:, :categorie_transmission] = [categorize_transmission(t) for t in valid[:, :transmission]]\n",
    "test[:, :categorie_transmission] = [categorize_transmission(t) for t in test[:, :transmission]]\n",
    "\n",
    "\n",
    "\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]\n",
    "\n",
    "\n",
    "train = select!(train, Not(:transmission, :type))\n",
    "valid = select!(valid, Not(:transmission, :type))\n",
    "test = select!(test, Not(:transmission, :type))\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:categorie_vehicule, :categorie_transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)\n",
    "\n",
    "\n",
    "# Define the target variable\n",
    "target = :consommation\n",
    "\n",
    "# Define the feature matrix and target vector\n",
    "X_train = Matrix(train[:, Not([target])])\n",
    "y_train = train[!, target]\n",
    "X_valid = Matrix(valid[:, Not([target])])\n",
    "y_valid = valid[!, target]\n",
    "X_test = Matrix(test)\n",
    "\n",
    "# Create interaction terms\n",
    "train.categorie_transmission_traction_vehicule_petits = train.categorie_transmission_traction .* train.categorie_vehicule_petits_véhicules\n",
    "train.categorie_transmission_traction_vehicule_moyens = train.categorie_transmission_traction .* train.categorie_vehicule_véhicules_moyens\n",
    "\n",
    "valid.categorie_transmission_traction_vehicule_petits = valid.categorie_transmission_traction .* valid.categorie_vehicule_petits_véhicules\n",
    "valid.categorie_transmission_traction_vehicule_moyens = valid.categorie_transmission_traction .* valid.categorie_vehicule_véhicules_moyens\n",
    "\n",
    "test.categorie_transmission_traction_vehicule_petits = test.categorie_transmission_traction .* test.categorie_vehicule_petits_véhicules\n",
    "test.categorie_transmission_traction_vehicule_moyens = test.categorie_transmission_traction .* test.categorie_vehicule_véhicules_moyens\n",
    "\n",
    "\n",
    "# Define the model\n",
    "# model = lm(@formula(consommation ~ age + transmission_4x4+ transmission_integrale + transmission_propulsion + transmission_traction + boite + cylindree), train)\n",
    "model = lm(@formula(consommation ~ age + categorie_transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_véhicules_moyens + boite + cylindree), train) #Meilleur\n",
    "# model = lm(@formula(consommation ~ age +  transmission_integrale + transmission_4x4 + transmission_traction + boite + cylindree), train)\n",
    "println(model)\n",
    "#cross validation\n",
    "data_k_folds = vcat(train, valid)\n",
    "y = data_k_folds.consommation\n",
    "X = select(data_k_folds, Not(:consommation))\n",
    "\n",
    "n = nrow(data_k_folds)\n",
    "k = 5\n",
    "fold_size = n ÷ k\n",
    "\n",
    "indices = randperm(n)\n",
    "\n",
    "rms_scores = []\n",
    "\n",
    "for i in 0:(k-1)\n",
    "    valid_indices = (i * fold_size + 1):((i + 1) * fold_size)\n",
    "    train_indices = setdiff(1:n, valid_indices)\n",
    "    \n",
    "    X_train = X[train_indices, :]\n",
    "    y_train = y[train_indices]\n",
    "    X_valid = X[valid_indices, :]\n",
    "    y_valid = y[valid_indices]\n",
    "    \n",
    "# model = lm(@formula(consommation ~ age + categorie_transmission_traction + categorie_vehicule_petits_véhicules + categorie_vehicule_véhicules_moyens + boite + cylindree), train) #Meilleur\n",
    " model = lm(@formula(consommation ~ age + categorie_transmission_traction + boite + cylindree), train) #Meilleur\n",
    "    \n",
    "    ŷ_valid = GLM.predict(model, X_valid)\n",
    "    rms = sqrt(mean((ŷ_valid .- y_valid).^2))\n",
    "    push!(rms_scores, rms)\n",
    "end\n",
    "\n",
    "moyenne_rmse = mean(rms_scores)\n",
    "println(\"Moyenne RMSE k-fold : $moyenne_rmse\")\n",
    "\n",
    "# Make predictions\n",
    "ŷ_train = GLM.predict(model, train)\n",
    "ŷ_valid = GLM.predict(model, valid)\n",
    "\n",
    "# Compute the RMSE\n",
    "rmse_train = sqrt(mean((ŷ_train .- train.consommation).^2))\n",
    "rmse_valid = sqrt(mean((ŷ_valid .- valid.consommation).^2))\n",
    "\n",
    "println(\"RMSE on the training set: $rmse_train\")\n",
    "println(\"RMSE on the validation set: $rmse_valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot dirstribtuion of residuals\n",
    "residuals = ŷ_valid .- valid.consommation\n",
    "h = histogram(residuals, bins=50, title=\"Distribution of residuals\", xlabel=\"Residuals\", ylabel=\"Frequency\")\n",
    "println(mean(residuals)) \n",
    "display(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Régression par l'approche des composantes principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TODO CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train = CSV.read(\"../data/raw/train.csv\", DataFrame; delim=\";\")\n",
    "test =  CSV.read(\"../data/raw/test.csv\", DataFrame; delim=\";\") #ne contient pas la varialbe consommation\n",
    "\n",
    "Random.seed!(1234) #pour la reproductibilit\n",
    "\n",
    "ntrain = round(Int, .8*nrow(full_train)) #80% des données pour l'entrainement: 80% * nb de lignes\n",
    "\n",
    "train_id = sample(1:nrow(full_train), ntrain, replace=false, ordered=true) #échantillonnage aléatoire pour l'entrainement\n",
    "valid_id = setdiff(1:nrow(full_train), train_id) #échantillon de validation. prend celles qui ne sont pas dans l'échantillon d'entrainement\n",
    "\n",
    "train = full_train[train_id, :]  \n",
    "valid = full_train[valid_id, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MultivariateStats\n",
    "using GLM\n",
    "\n",
    "# Data Cleaning and Preparation\n",
    "Random.seed!(1234) # For reproducibility\n",
    "\n",
    "# Split the data\n",
    "ntrain = round(Int, 0.8 * nrow(full_train))\n",
    "train_id = sample(1:nrow(full_train), ntrain; replace=false, ordered=true)\n",
    "valid_id = setdiff(1:nrow(full_train), train_id)\n",
    "\n",
    "train = full_train[train_id, :]\n",
    "valid = full_train[valid_id, :]\n",
    "\n",
    "\n",
    "# Pour le DataFrame 'train'\n",
    "train[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in train[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'valid'\n",
    "valid[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in valid[:, :type]]\n",
    "\n",
    "# Pour le DataFrame 'test'\n",
    "test[:, :categorie_vehicule] = [categorize_vehicle_type(t) for t in test[:, :type]]\n",
    "\n",
    "# Créer la variable 'categorie_transmission' dans les trois DataFrames\n",
    "train[:, :categorie_transmission] = [categorize_transmission(t) for t in train[:, :transmission]]\n",
    "valid[:, :categorie_transmission] = [categorize_transmission(t) for t in valid[:, :transmission]]\n",
    "test[:, :categorie_transmission] = [categorize_transmission(t) for t in test[:, :transmission]]\n",
    "\n",
    "\n",
    "\n",
    "# remove type column\n",
    "train = select!(train, Not(:transmission, :type))\n",
    "valid = select!(valid, Not(:transmission, :type))\n",
    "test = select!(test, Not(:transmission, :type))\n",
    "\n",
    "\n",
    "# Data cleaning\n",
    "for col in [:cylindree, :consommation]\n",
    "    train[!, col] = replace.(train[!, col], \",\" => \".\")\n",
    "    valid[!, col] = replace.(valid[!, col], \",\" => \".\")\n",
    "    train[!, col] = safe_parse_float.(train[!, col])\n",
    "    valid[!, col] = safe_parse_float.(valid[!, col])\n",
    "end\n",
    "\n",
    "for col in [:cylindree,]\n",
    "    test[!, col] = replace.(test[!, col], \",\" => \".\")\n",
    "    test[!, col] = safe_parse_float.(test[!, col])\n",
    "end\n",
    "\n",
    "train.cylindree = log.(train.cylindree .+ 1)\n",
    "valid.cylindree = log.(valid.cylindree.+ 1)\n",
    "test.cylindree = log.(test.cylindree.+ 1)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = [:categorie_vehicule, :categorie_transmission]\n",
    "\n",
    "# Collect unique levels from the training set\n",
    "levels_dict = Dict()\n",
    "for col in categorical_cols\n",
    "    levels_dict[col] = unique(train[!, col])\n",
    "end\n",
    "\n",
    "train = one_hot_encode(train, categorical_cols, levels_dict)\n",
    "valid = one_hot_encode(valid, categorical_cols, levels_dict)\n",
    "test = one_hot_encode(test, categorical_cols, levels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric columns\n",
    "numeric_cols = setdiff(names(train)[eltype.(eachcol(train)) .<: Real], [\"consommation\"])\n",
    "\n",
    "println(\"Numeric columns: \", numeric_cols)\n",
    "\n",
    "# Extract numeric columns\n",
    "X_train = Matrix(select(train, numeric_cols))\n",
    "y_train = Vector(train.consommation)\n",
    "X_valid = Matrix(select(valid, numeric_cols))\n",
    "\n",
    "# Standardize the data (commented out)\n",
    "# X_mean = mean(X_train; dims=1)\n",
    "# X_stddev = std(X_train; dims=1, corrected=false)\n",
    "# X_train_std = (X_train .- X_mean) ./ X_stddev\n",
    "# X_valid_std = (X_valid .- X_mean) ./ X_stddev\n",
    "\n",
    "# Perform PCA\n",
    "pca_model = fit(PCA, X_train'; maxoutdim=5)  # Use original data without standardization\n",
    "Z_train = MultivariateStats.transform(pca_model, X_train')'\n",
    "Z_valid = MultivariateStats.transform(pca_model, X_valid')'\n",
    "\n",
    "# Add principal components to DataFrames (train and valid)\n",
    "for i in 1:size(Z_train, 2)\n",
    "    train[:, \"PC$(i)\"] = Z_train[:, i]\n",
    "    valid[:, \"PC$(i)\"] = Z_valid[:, i]\n",
    "end\n",
    "\n",
    "# Fit a regression model using PCA\n",
    "model_with_pca = lm(@formula(consommation ~ PC1 + PC2 + PC3 + PC4 + PC5), train)\n",
    "\n",
    "# Predict on validation data\n",
    "valid_prediction_with_pca = predict(model_with_pca, valid)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_with_pca = sqrt(mean((valid_prediction_with_pca - valid.consommation).^2))\n",
    "println(\"RMSE with PCA: \", rmse_with_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x̄ = vec(mean(X, dims=1))\n",
    "\n",
    "Z = X .- x̄'\n",
    "\n",
    "F = svd(Z)\n",
    "V = F.V\n",
    "U = F.U\n",
    "γ = F.S;\n",
    "\n",
    "cumvar = cumsum(γ.^2)\n",
    "\n",
    "ratio = cumvar / cumvar[end]\n",
    "\n",
    "df = DataFrame(k = Int64[], Variance = Float64[])\n",
    "\n",
    "for k in 1:length(ratio)\n",
    "    push!(df, [k, ratio[k]])\n",
    "end\n",
    "\n",
    "Gadfly.plot(df, x=:k, y=:Variance, Geom.line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Impact des échelles dans les données\n",
    "Dans les données non standardisées, les variables explicatives ayant des valeurs plus grandes peuvent dominer la variance totale, ce qui oriente la PCA vers ces variables. Si ces variables sont fortement corrélées avec la variable cible (\n",
    "𝑌\n",
    "Y), alors le modèle peut accidentellement mieux capturer cette relation.\n",
    "En revanche, la standardisation neutralise les différences d'échelle, ce qui peut diluer l'effet des variables dominantes, même si elles ont une forte corrélation avec \n",
    "𝑌\n",
    "Y.\n",
    "Explication potentielle :\n",
    "Dans votre jeu de données, il est possible qu'une ou plusieurs variables avec des échelles plus grandes soient prédictives de \n",
    "𝑌\n",
    "Y, et la méthode non standardisée en profite directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Sur-ajustement (Overfitting)\n",
    "La méthode non standardisée applique la PCA sur les données d'origine, mais utilise ensuite les données reconstruites (\n",
    "𝑋\n",
    "𝑟\n",
    "X \n",
    "r\n",
    "​\n",
    " ) pour l'entraînement. Cela peut réintroduire une grande partie des informations originales, y compris le bruit ou les corrélations spurielles, ce qui peut conduire à un modèle sur-ajusté.\n",
    "Si l'ensemble de validation est similaire à l'ensemble d'entraînement (par exemple, s'il provient de la même distribution ou a des caractéristiques similaires), un sur-ajustement peut donner des RMSE artificiellement bas.\n",
    "Explication potentielle :\n",
    "Votre validation pourrait être moins rigoureuse, et la méthode non standardisée exploite des relations non généralisables dans les données.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Le fait que la méthode non standardisée donne un meilleur RMSE peut s'expliquer par plusieurs raisons, mais cela ne signifie pas nécessairement qu'elle est meilleure ou qu'elle respecte les principes statistiques sous-jacents. Explorons pourquoi cela pourrait se produire :\n",
    "\n",
    "1. Impact des échelles dans les données\n",
    "Dans les données non standardisées, les variables explicatives ayant des valeurs plus grandes peuvent dominer la variance totale, ce qui oriente la PCA vers ces variables. Si ces variables sont fortement corrélées avec la variable cible (\n",
    "𝑌\n",
    "Y), alors le modèle peut accidentellement mieux capturer cette relation.\n",
    "En revanche, la standardisation neutralise les différences d'échelle, ce qui peut diluer l'effet des variables dominantes, même si elles ont une forte corrélation avec \n",
    "𝑌\n",
    "Y.\n",
    "Explication potentielle :\n",
    "Dans votre jeu de données, il est possible qu'une ou plusieurs variables avec des échelles plus grandes soient prédictives de \n",
    "𝑌\n",
    "Y, et la méthode non standardisée en profite directement.\n",
    "\n",
    "2. Sur-ajustement (Overfitting)\n",
    "La méthode non standardisée applique la PCA sur les données d'origine, mais utilise ensuite les données reconstruites (\n",
    "𝑋\n",
    "𝑟\n",
    "X \n",
    "r\n",
    "​\n",
    " ) pour l'entraînement. Cela peut réintroduire une grande partie des informations originales, y compris le bruit ou les corrélations spurielles, ce qui peut conduire à un modèle sur-ajusté.\n",
    "Si l'ensemble de validation est similaire à l'ensemble d'entraînement (par exemple, s'il provient de la même distribution ou a des caractéristiques similaires), un sur-ajustement peut donner des RMSE artificiellement bas.\n",
    "Explication potentielle :\n",
    "Votre validation pourrait être moins rigoureuse, et la méthode non standardisée exploite des relations non généralisables dans les données.\n",
    "\n",
    "3. Corrélation forte entre les variables\n",
    "Si les variables explicatives ont une forte corrélation intrinsèque, l'analyse en composantes principales standardisée peut répartir cette information sur plusieurs composantes. Cela réduit la capacité du modèle à se concentrer sur des variables fortement corrélées avec \n",
    "𝑌\n",
    "Y.\n",
    "La méthode non standardisée, en revanche, conserve ces corrélations et peut donc mieux modéliser la relation entre \n",
    "𝑋\n",
    "X et \n",
    "𝑌\n",
    "Y.\n",
    "Explication potentielle :\n",
    "Les corrélations fortes dans vos données favorisent la méthode non standardisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Effet des données reconstruites\n",
    "Dans la méthode non standardisée, vous utilisez des données reconstruites (\n",
    "𝑋\n",
    "𝑟\n",
    "X \n",
    "r\n",
    "​\n",
    " ), qui incluent une grande partie de l'information originale. Cela signifie que la régression est moins influencée par la réduction de dimension et plus proche de la régression sur les données d'origine.\n",
    "En revanche, dans la méthode standardisée, seules les composantes principales sont utilisées, ce qui peut sacrifier une partie de l'information pour réduire la multicolinéarité et améliorer la généralisation.\n",
    "Explication potentielle :\n",
    "L'utilisation des données reconstruites dans la méthode non standardisée maintient plus d'information, ce qui peut donner un RMSE plus faible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Problème avec la PCA standardisée\n",
    "Si la standardisation n'est pas appropriée (par exemple, si certaines variables explicatives sont presque constantes ou si elles sont déjà sur des échelles comparables), alors l'analyse en composantes principales standardisée peut ne pas capturer efficacement les directions principales de la variance.\n",
    "Cela peut entraîner une perte d'information utile, ce qui affecte les performances du modèle.\n",
    "Explication potentielle :\n",
    "Les variables de votre jeu de données n'ont peut-être pas besoin d'être standardisées ou la standardisation introduit un biais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
